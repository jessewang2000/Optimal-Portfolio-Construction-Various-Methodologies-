{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1w75W6Mfoegr"
   },
   "source": [
    "## Returns Classification using Numerous Approaches\n",
    "- Data source: CRSP\n",
    "- Sample period: 2000/1-2018/12\n",
    "* File name: crsp_filtered2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "-IeNov1RoVL5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from IPython.display import display\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "# pd.set_option('display.max_rows', 100, 'display.min_rows', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "3BxCFmH3od3x"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(15,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 626
    },
    "id": "Fh_9ytbZor-5",
    "outputId": "7fcc765d-ab5f-4862-a036-654d497c9834"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>permno</th>\n",
       "      <th>prc</th>\n",
       "      <th>ret</th>\n",
       "      <th>relvol</th>\n",
       "      <th>size</th>\n",
       "      <th>prc_clipped</th>\n",
       "      <th>relvol_clipped</th>\n",
       "      <th>size_clipped</th>\n",
       "      <th>tgt_ret</th>\n",
       "      <th>tgt_label</th>\n",
       "      <th>mom3m</th>\n",
       "      <th>mom6m</th>\n",
       "      <th>mom12m</th>\n",
       "      <th>sz_cat</th>\n",
       "      <th>tgt_label2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>2001-01-31</td>\n",
       "      <td>80000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.025478</td>\n",
       "      <td>0.052441</td>\n",
       "      <td>11.180602</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.052441</td>\n",
       "      <td>11.180602</td>\n",
       "      <td>-0.003106</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.019481</td>\n",
       "      <td>0.226563</td>\n",
       "      <td>0.171642</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>2001-02-28</td>\n",
       "      <td>80000</td>\n",
       "      <td>20.062500</td>\n",
       "      <td>-0.003106</td>\n",
       "      <td>0.023352</td>\n",
       "      <td>11.151626</td>\n",
       "      <td>20.062500</td>\n",
       "      <td>0.023352</td>\n",
       "      <td>11.151626</td>\n",
       "      <td>0.099688</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.080537</td>\n",
       "      <td>0.183824</td>\n",
       "      <td>0.229008</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>2001-03-30</td>\n",
       "      <td>80000</td>\n",
       "      <td>22.062500</td>\n",
       "      <td>0.099688</td>\n",
       "      <td>0.072649</td>\n",
       "      <td>11.244636</td>\n",
       "      <td>22.062500</td>\n",
       "      <td>0.072649</td>\n",
       "      <td>11.244636</td>\n",
       "      <td>-0.027989</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.022293</td>\n",
       "      <td>0.163043</td>\n",
       "      <td>0.360169</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>2001-04-30</td>\n",
       "      <td>80000</td>\n",
       "      <td>21.445000</td>\n",
       "      <td>-0.027989</td>\n",
       "      <td>0.055857</td>\n",
       "      <td>11.216248</td>\n",
       "      <td>21.445000</td>\n",
       "      <td>0.055857</td>\n",
       "      <td>11.216248</td>\n",
       "      <td>0.010026</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.096273</td>\n",
       "      <td>0.146104</td>\n",
       "      <td>0.548246</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>2001-05-31</td>\n",
       "      <td>80000</td>\n",
       "      <td>21.660000</td>\n",
       "      <td>0.010026</td>\n",
       "      <td>0.025983</td>\n",
       "      <td>11.231117</td>\n",
       "      <td>21.660000</td>\n",
       "      <td>0.025983</td>\n",
       "      <td>11.231117</td>\n",
       "      <td>-0.021237</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.068910</td>\n",
       "      <td>0.151409</td>\n",
       "      <td>0.394797</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313618</th>\n",
       "      <td>609240</td>\n",
       "      <td>2018-06-29</td>\n",
       "      <td>93436</td>\n",
       "      <td>342.950012</td>\n",
       "      <td>0.204474</td>\n",
       "      <td>1.252693</td>\n",
       "      <td>17.884169</td>\n",
       "      <td>129.470001</td>\n",
       "      <td>1.124182</td>\n",
       "      <td>17.391356</td>\n",
       "      <td>-0.130660</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.069891</td>\n",
       "      <td>-0.085499</td>\n",
       "      <td>-0.212605</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313619</th>\n",
       "      <td>609241</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>93436</td>\n",
       "      <td>298.140015</td>\n",
       "      <td>-0.130660</td>\n",
       "      <td>1.010565</td>\n",
       "      <td>17.744599</td>\n",
       "      <td>129.470001</td>\n",
       "      <td>1.010565</td>\n",
       "      <td>17.391356</td>\n",
       "      <td>0.011806</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.166894</td>\n",
       "      <td>-0.032062</td>\n",
       "      <td>0.060222</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313620</th>\n",
       "      <td>609242</td>\n",
       "      <td>2018-08-31</td>\n",
       "      <td>93436</td>\n",
       "      <td>301.660004</td>\n",
       "      <td>0.011806</td>\n",
       "      <td>1.625692</td>\n",
       "      <td>17.756336</td>\n",
       "      <td>129.470001</td>\n",
       "      <td>1.124182</td>\n",
       "      <td>17.391356</td>\n",
       "      <td>-0.122290</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047097</td>\n",
       "      <td>-0.130939</td>\n",
       "      <td>-0.162293</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313621</th>\n",
       "      <td>609243</td>\n",
       "      <td>2018-09-28</td>\n",
       "      <td>93436</td>\n",
       "      <td>264.769989</td>\n",
       "      <td>-0.122290</td>\n",
       "      <td>1.142785</td>\n",
       "      <td>17.631655</td>\n",
       "      <td>129.470001</td>\n",
       "      <td>1.124182</td>\n",
       "      <td>17.391356</td>\n",
       "      <td>0.274011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.120397</td>\n",
       "      <td>0.133506</td>\n",
       "      <td>-0.115626</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313622</th>\n",
       "      <td>609244</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>93436</td>\n",
       "      <td>337.320007</td>\n",
       "      <td>0.274011</td>\n",
       "      <td>1.667840</td>\n",
       "      <td>17.874728</td>\n",
       "      <td>129.470001</td>\n",
       "      <td>1.124182</td>\n",
       "      <td>17.391356</td>\n",
       "      <td>0.039013</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.111927</td>\n",
       "      <td>-0.099115</td>\n",
       "      <td>-0.201369</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>313623 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0        date  permno         prc       ret    relvol  \\\n",
       "0               12  2001-01-31   80000   20.125000  0.025478  0.052441   \n",
       "1               13  2001-02-28   80000   20.062500 -0.003106  0.023352   \n",
       "2               14  2001-03-30   80000   22.062500  0.099688  0.072649   \n",
       "3               15  2001-04-30   80000   21.445000 -0.027989  0.055857   \n",
       "4               16  2001-05-31   80000   21.660000  0.010026  0.025983   \n",
       "...            ...         ...     ...         ...       ...       ...   \n",
       "313618      609240  2018-06-29   93436  342.950012  0.204474  1.252693   \n",
       "313619      609241  2018-07-31   93436  298.140015 -0.130660  1.010565   \n",
       "313620      609242  2018-08-31   93436  301.660004  0.011806  1.625692   \n",
       "313621      609243  2018-09-28   93436  264.769989 -0.122290  1.142785   \n",
       "313622      609244  2018-10-31   93436  337.320007  0.274011  1.667840   \n",
       "\n",
       "             size  prc_clipped  relvol_clipped  size_clipped   tgt_ret  \\\n",
       "0       11.180602    20.125000        0.052441     11.180602 -0.003106   \n",
       "1       11.151626    20.062500        0.023352     11.151626  0.099688   \n",
       "2       11.244636    22.062500        0.072649     11.244636 -0.027989   \n",
       "3       11.216248    21.445000        0.055857     11.216248  0.010026   \n",
       "4       11.231117    21.660000        0.025983     11.231117 -0.021237   \n",
       "...           ...          ...             ...           ...       ...   \n",
       "313618  17.884169   129.470001        1.124182     17.391356 -0.130660   \n",
       "313619  17.744599   129.470001        1.010565     17.391356  0.011806   \n",
       "313620  17.756336   129.470001        1.124182     17.391356 -0.122290   \n",
       "313621  17.631655   129.470001        1.124182     17.391356  0.274011   \n",
       "313622  17.874728   129.470001        1.124182     17.391356  0.039013   \n",
       "\n",
       "        tgt_label     mom3m     mom6m    mom12m  sz_cat  tgt_label2  \n",
       "0             3.0  0.019481  0.226563  0.171642       5         0.0  \n",
       "1             1.0  0.080537  0.183824  0.229008       5         1.0  \n",
       "2             6.0  0.022293  0.163043  0.360169       5        -1.0  \n",
       "3             5.0  0.096273  0.146104  0.548246       5         1.0  \n",
       "4             5.0  0.068910  0.151409  0.394797       5        -1.0  \n",
       "...           ...       ...       ...       ...     ...         ...  \n",
       "313618        9.0  0.069891 -0.085499 -0.212605       0        -1.0  \n",
       "313619        5.0  0.166894 -0.032062  0.060222       0         1.0  \n",
       "313620        8.0  0.047097 -0.130939 -0.162293       0        -1.0  \n",
       "313621        0.0 -0.120397  0.133506 -0.115626       0         1.0  \n",
       "313622        3.0 -0.111927 -0.099115 -0.201369       0         1.0  \n",
       "\n",
       "[313623 rows x 17 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crsp = pd.read_csv('crsp_filtered2.csv')\n",
    "crsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "iISQ779QouJ5"
   },
   "outputs": [],
   "source": [
    "# create copy for use \n",
    "crsp2 = crsp.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-dap13fo2kO"
   },
   "source": [
    "## Step: Feature Selection\n",
    "#### Checking for correlation among features and testing correlation between feature and Y variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 534
    },
    "id": "tnKXGV0CpDiM",
    "outputId": "2e45c5e6-8908-457d-a01b-d1b730c85fe5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>prc</th>\n",
       "      <th>ret</th>\n",
       "      <th>relvol</th>\n",
       "      <th>size</th>\n",
       "      <th>prc_clipped</th>\n",
       "      <th>relvol_clipped</th>\n",
       "      <th>size_clipped</th>\n",
       "      <th>tgt_ret</th>\n",
       "      <th>tgt_label</th>\n",
       "      <th>mom3m</th>\n",
       "      <th>mom6m</th>\n",
       "      <th>mom12m</th>\n",
       "      <th>sz_cat</th>\n",
       "      <th>tgt_label2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>permno</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.007688</td>\n",
       "      <td>-0.005794</td>\n",
       "      <td>0.021004</td>\n",
       "      <td>0.061366</td>\n",
       "      <td>-0.002116</td>\n",
       "      <td>0.023692</td>\n",
       "      <td>0.060884</td>\n",
       "      <td>-0.003234</td>\n",
       "      <td>0.006260</td>\n",
       "      <td>-0.005256</td>\n",
       "      <td>-0.003051</td>\n",
       "      <td>-0.005066</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>-0.002314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prc</th>\n",
       "      <td>-0.007688</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006345</td>\n",
       "      <td>0.020708</td>\n",
       "      <td>0.313192</td>\n",
       "      <td>0.506202</td>\n",
       "      <td>0.031349</td>\n",
       "      <td>0.301154</td>\n",
       "      <td>-0.003107</td>\n",
       "      <td>-0.009878</td>\n",
       "      <td>0.009908</td>\n",
       "      <td>0.013717</td>\n",
       "      <td>0.020935</td>\n",
       "      <td>-0.220862</td>\n",
       "      <td>-0.002086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ret</th>\n",
       "      <td>-0.005794</td>\n",
       "      <td>0.006345</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083804</td>\n",
       "      <td>-0.013514</td>\n",
       "      <td>0.019250</td>\n",
       "      <td>0.030337</td>\n",
       "      <td>-0.013689</td>\n",
       "      <td>0.010015</td>\n",
       "      <td>0.028435</td>\n",
       "      <td>-0.005804</td>\n",
       "      <td>0.006362</td>\n",
       "      <td>-0.002186</td>\n",
       "      <td>0.006074</td>\n",
       "      <td>-0.010484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relvol</th>\n",
       "      <td>0.021004</td>\n",
       "      <td>0.020708</td>\n",
       "      <td>0.083804</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.152354</td>\n",
       "      <td>0.064174</td>\n",
       "      <td>0.818717</td>\n",
       "      <td>0.155663</td>\n",
       "      <td>-0.025182</td>\n",
       "      <td>0.029720</td>\n",
       "      <td>0.064084</td>\n",
       "      <td>0.088096</td>\n",
       "      <td>0.136380</td>\n",
       "      <td>-0.183620</td>\n",
       "      <td>-0.030425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size</th>\n",
       "      <td>0.061366</td>\n",
       "      <td>0.313192</td>\n",
       "      <td>-0.013514</td>\n",
       "      <td>0.152354</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.632779</td>\n",
       "      <td>0.226533</td>\n",
       "      <td>0.998444</td>\n",
       "      <td>-0.016058</td>\n",
       "      <td>-0.009333</td>\n",
       "      <td>-0.009968</td>\n",
       "      <td>-0.009297</td>\n",
       "      <td>-0.000533</td>\n",
       "      <td>-0.874910</td>\n",
       "      <td>-0.020173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prc_clipped</th>\n",
       "      <td>-0.002116</td>\n",
       "      <td>0.506202</td>\n",
       "      <td>0.019250</td>\n",
       "      <td>0.064174</td>\n",
       "      <td>0.632779</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.095014</td>\n",
       "      <td>0.627700</td>\n",
       "      <td>-0.009143</td>\n",
       "      <td>-0.019779</td>\n",
       "      <td>0.028446</td>\n",
       "      <td>0.039183</td>\n",
       "      <td>0.057942</td>\n",
       "      <td>-0.495857</td>\n",
       "      <td>-0.009074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relvol_clipped</th>\n",
       "      <td>0.023692</td>\n",
       "      <td>0.031349</td>\n",
       "      <td>0.030337</td>\n",
       "      <td>0.818717</td>\n",
       "      <td>0.226533</td>\n",
       "      <td>0.095014</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.231231</td>\n",
       "      <td>-0.026625</td>\n",
       "      <td>0.030291</td>\n",
       "      <td>0.038212</td>\n",
       "      <td>0.070824</td>\n",
       "      <td>0.114113</td>\n",
       "      <td>-0.270389</td>\n",
       "      <td>-0.037335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size_clipped</th>\n",
       "      <td>0.060884</td>\n",
       "      <td>0.301154</td>\n",
       "      <td>-0.013689</td>\n",
       "      <td>0.155663</td>\n",
       "      <td>0.998444</td>\n",
       "      <td>0.627700</td>\n",
       "      <td>0.231231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.016290</td>\n",
       "      <td>-0.009100</td>\n",
       "      <td>-0.010154</td>\n",
       "      <td>-0.009509</td>\n",
       "      <td>-0.000656</td>\n",
       "      <td>-0.880705</td>\n",
       "      <td>-0.020741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tgt_ret</th>\n",
       "      <td>-0.003234</td>\n",
       "      <td>-0.003107</td>\n",
       "      <td>0.010015</td>\n",
       "      <td>-0.025182</td>\n",
       "      <td>-0.016058</td>\n",
       "      <td>-0.009143</td>\n",
       "      <td>-0.026625</td>\n",
       "      <td>-0.016290</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.795261</td>\n",
       "      <td>0.010333</td>\n",
       "      <td>0.015075</td>\n",
       "      <td>0.017189</td>\n",
       "      <td>0.014412</td>\n",
       "      <td>0.654787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tgt_label</th>\n",
       "      <td>0.006260</td>\n",
       "      <td>-0.009878</td>\n",
       "      <td>0.028435</td>\n",
       "      <td>0.029720</td>\n",
       "      <td>-0.009333</td>\n",
       "      <td>-0.019779</td>\n",
       "      <td>0.030291</td>\n",
       "      <td>-0.009100</td>\n",
       "      <td>-0.795261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000385</td>\n",
       "      <td>-0.007081</td>\n",
       "      <td>-0.008336</td>\n",
       "      <td>0.007331</td>\n",
       "      <td>-0.726055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mom3m</th>\n",
       "      <td>-0.005256</td>\n",
       "      <td>0.009908</td>\n",
       "      <td>-0.005804</td>\n",
       "      <td>0.064084</td>\n",
       "      <td>-0.009968</td>\n",
       "      <td>0.028446</td>\n",
       "      <td>0.038212</td>\n",
       "      <td>-0.010154</td>\n",
       "      <td>0.010333</td>\n",
       "      <td>-0.000385</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.558244</td>\n",
       "      <td>0.289128</td>\n",
       "      <td>0.006791</td>\n",
       "      <td>-0.001518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mom6m</th>\n",
       "      <td>-0.003051</td>\n",
       "      <td>0.013717</td>\n",
       "      <td>0.006362</td>\n",
       "      <td>0.088096</td>\n",
       "      <td>-0.009297</td>\n",
       "      <td>0.039183</td>\n",
       "      <td>0.070824</td>\n",
       "      <td>-0.009509</td>\n",
       "      <td>0.015075</td>\n",
       "      <td>-0.007081</td>\n",
       "      <td>0.558244</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.478092</td>\n",
       "      <td>0.012080</td>\n",
       "      <td>-0.001507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mom12m</th>\n",
       "      <td>-0.005066</td>\n",
       "      <td>0.020935</td>\n",
       "      <td>-0.002186</td>\n",
       "      <td>0.136380</td>\n",
       "      <td>-0.000533</td>\n",
       "      <td>0.057942</td>\n",
       "      <td>0.114113</td>\n",
       "      <td>-0.000656</td>\n",
       "      <td>0.017189</td>\n",
       "      <td>-0.008336</td>\n",
       "      <td>0.289128</td>\n",
       "      <td>0.478092</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006019</td>\n",
       "      <td>-0.002096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sz_cat</th>\n",
       "      <td>0.029900</td>\n",
       "      <td>-0.220862</td>\n",
       "      <td>0.006074</td>\n",
       "      <td>-0.183620</td>\n",
       "      <td>-0.874910</td>\n",
       "      <td>-0.495857</td>\n",
       "      <td>-0.270389</td>\n",
       "      <td>-0.880705</td>\n",
       "      <td>0.014412</td>\n",
       "      <td>0.007331</td>\n",
       "      <td>0.006791</td>\n",
       "      <td>0.012080</td>\n",
       "      <td>0.006019</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tgt_label2</th>\n",
       "      <td>-0.002314</td>\n",
       "      <td>-0.002086</td>\n",
       "      <td>-0.010484</td>\n",
       "      <td>-0.030425</td>\n",
       "      <td>-0.020173</td>\n",
       "      <td>-0.009074</td>\n",
       "      <td>-0.037335</td>\n",
       "      <td>-0.020741</td>\n",
       "      <td>0.654787</td>\n",
       "      <td>-0.726055</td>\n",
       "      <td>-0.001518</td>\n",
       "      <td>-0.001507</td>\n",
       "      <td>-0.002096</td>\n",
       "      <td>0.017177</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  permno       prc       ret    relvol      size  prc_clipped  \\\n",
       "permno          1.000000 -0.007688 -0.005794  0.021004  0.061366    -0.002116   \n",
       "prc            -0.007688  1.000000  0.006345  0.020708  0.313192     0.506202   \n",
       "ret            -0.005794  0.006345  1.000000  0.083804 -0.013514     0.019250   \n",
       "relvol          0.021004  0.020708  0.083804  1.000000  0.152354     0.064174   \n",
       "size            0.061366  0.313192 -0.013514  0.152354  1.000000     0.632779   \n",
       "prc_clipped    -0.002116  0.506202  0.019250  0.064174  0.632779     1.000000   \n",
       "relvol_clipped  0.023692  0.031349  0.030337  0.818717  0.226533     0.095014   \n",
       "size_clipped    0.060884  0.301154 -0.013689  0.155663  0.998444     0.627700   \n",
       "tgt_ret        -0.003234 -0.003107  0.010015 -0.025182 -0.016058    -0.009143   \n",
       "tgt_label       0.006260 -0.009878  0.028435  0.029720 -0.009333    -0.019779   \n",
       "mom3m          -0.005256  0.009908 -0.005804  0.064084 -0.009968     0.028446   \n",
       "mom6m          -0.003051  0.013717  0.006362  0.088096 -0.009297     0.039183   \n",
       "mom12m         -0.005066  0.020935 -0.002186  0.136380 -0.000533     0.057942   \n",
       "sz_cat          0.029900 -0.220862  0.006074 -0.183620 -0.874910    -0.495857   \n",
       "tgt_label2     -0.002314 -0.002086 -0.010484 -0.030425 -0.020173    -0.009074   \n",
       "\n",
       "                relvol_clipped  size_clipped   tgt_ret  tgt_label     mom3m  \\\n",
       "permno                0.023692      0.060884 -0.003234   0.006260 -0.005256   \n",
       "prc                   0.031349      0.301154 -0.003107  -0.009878  0.009908   \n",
       "ret                   0.030337     -0.013689  0.010015   0.028435 -0.005804   \n",
       "relvol                0.818717      0.155663 -0.025182   0.029720  0.064084   \n",
       "size                  0.226533      0.998444 -0.016058  -0.009333 -0.009968   \n",
       "prc_clipped           0.095014      0.627700 -0.009143  -0.019779  0.028446   \n",
       "relvol_clipped        1.000000      0.231231 -0.026625   0.030291  0.038212   \n",
       "size_clipped          0.231231      1.000000 -0.016290  -0.009100 -0.010154   \n",
       "tgt_ret              -0.026625     -0.016290  1.000000  -0.795261  0.010333   \n",
       "tgt_label             0.030291     -0.009100 -0.795261   1.000000 -0.000385   \n",
       "mom3m                 0.038212     -0.010154  0.010333  -0.000385  1.000000   \n",
       "mom6m                 0.070824     -0.009509  0.015075  -0.007081  0.558244   \n",
       "mom12m                0.114113     -0.000656  0.017189  -0.008336  0.289128   \n",
       "sz_cat               -0.270389     -0.880705  0.014412   0.007331  0.006791   \n",
       "tgt_label2           -0.037335     -0.020741  0.654787  -0.726055 -0.001518   \n",
       "\n",
       "                   mom6m    mom12m    sz_cat  tgt_label2  \n",
       "permno         -0.003051 -0.005066  0.029900   -0.002314  \n",
       "prc             0.013717  0.020935 -0.220862   -0.002086  \n",
       "ret             0.006362 -0.002186  0.006074   -0.010484  \n",
       "relvol          0.088096  0.136380 -0.183620   -0.030425  \n",
       "size           -0.009297 -0.000533 -0.874910   -0.020173  \n",
       "prc_clipped     0.039183  0.057942 -0.495857   -0.009074  \n",
       "relvol_clipped  0.070824  0.114113 -0.270389   -0.037335  \n",
       "size_clipped   -0.009509 -0.000656 -0.880705   -0.020741  \n",
       "tgt_ret         0.015075  0.017189  0.014412    0.654787  \n",
       "tgt_label      -0.007081 -0.008336  0.007331   -0.726055  \n",
       "mom3m           0.558244  0.289128  0.006791   -0.001518  \n",
       "mom6m           1.000000  0.478092  0.012080   -0.001507  \n",
       "mom12m          0.478092  1.000000  0.006019   -0.002096  \n",
       "sz_cat          0.012080  0.006019  1.000000    0.017177  \n",
       "tgt_label2     -0.001507 -0.002096  0.017177    1.000000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature selection \n",
    "\n",
    "#checking feature correlation \n",
    "corr = crsp2.iloc[:,2:17]\n",
    "corr2 = corr.corr() \n",
    "corr2  #insights - 1) remove prc, relvol, size, tgt_ret, size_clipped - too much correlation between other features; 2) tgt_ret - super high correlation with tgt_label - will overstate\n",
    "#note: some correlation among different momentum features, size and prc; did not remove because correlation not too high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yd4ksKcLpOkm"
   },
   "source": [
    "#### Conduct Test-Train Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "IS5ruGIDpQyO"
   },
   "outputs": [],
   "source": [
    "# train set: ~ 2009-12-31\n",
    "# test set: 2010-01-01 ~\n",
    "train = crsp2[crsp2.date < '2010-01-01']\n",
    "test = crsp2[crsp2.date >= '2010-01-01']\n",
    "\n",
    "x_cols = ['permno','ret','prc_clipped','relvol_clipped','sz_cat','mom3m','mom6m','mom12m'] # input features\n",
    "x_train = train[x_cols]\n",
    "y_train1 = train['tgt_label'] #using tgt_label\n",
    "y_train2 = train['tgt_label2']\n",
    "x_test = test[x_cols]\n",
    "y_test1 = test['tgt_label']\n",
    "y_test2 = test['tgt_label2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize the training & test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJcdP-cepbHQ"
   },
   "source": [
    "### ML Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, train_test_split, GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GiQrHqWqpfXu"
   },
   "source": [
    "## Classification Process\n",
    "### Logistic Regression Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "43Hvq-Ziptqd"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Bo-WAWrcqNW0"
   },
   "outputs": [],
   "source": [
    "# define the multinomial logistic regression model\n",
    "mlr = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "mlr_tgt1 = mlr.fit(x_train, y_train1)\n",
    "mlr_tgt2 = mlr.fit(x_train, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yGkIJAtnqQYB",
    "outputId": "83eb599b-acd8-46d8-e383-6ee75b0fd5b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00392732, -0.00792271, -0.04966147,  0.11902129, -0.06070932,\n",
       "        -0.00200098, -0.01410747,  0.00647922],\n",
       "       [ 0.01657376,  0.01815165,  0.14118607, -0.16468738,  0.10098323,\n",
       "         0.01756037, -0.00166798, -0.00200363],\n",
       "       [-0.02050108, -0.01022894, -0.0915246 ,  0.04566609, -0.04027392,\n",
       "        -0.01555939,  0.01577545, -0.00447559]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regression coefficient and intercept\n",
    "mlr_tgt1.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ty_1GK7qh6x",
    "outputId": "0eb3e94c-b5a4-4c6b-a6f8-45dc7fcf94b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00392732, -0.00792271, -0.04966147,  0.11902129, -0.06070932,\n",
       "        -0.00200098, -0.01410747,  0.00647922],\n",
       "       [ 0.01657376,  0.01815165,  0.14118607, -0.16468738,  0.10098323,\n",
       "         0.01756037, -0.00166798, -0.00200363],\n",
       "       [-0.02050108, -0.01022894, -0.0915246 ,  0.04566609, -0.04027392,\n",
       "        -0.01555939,  0.01577545, -0.00447559]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr_tgt2.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zB0Ak7XvFrM"
   },
   "source": [
    "### Decision Trees Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "DS-UC20lvImn"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "N9hFArE0vLwt"
   },
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier(max_depth=5, min_samples_split=2, criterion = \"gini\")\n",
    "dtree1 = dtree.fit(x_train, y_train1)\n",
    "dtree2 = dtree.fit(x_train,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "id": "0GLQw3Uwz4Cz",
    "outputId": "849ca4c3-ffe3-4677-c0d0-125036af0b11"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prc_clipped</th>\n",
       "      <td>0.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relvol_clipped</th>\n",
       "      <td>0.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mom12m</th>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>permno</th>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ret</th>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mom6m</th>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sz_cat</th>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mom3m</th>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                importance\n",
       "feature                   \n",
       "prc_clipped          0.719\n",
       "relvol_clipped       0.135\n",
       "mom12m               0.083\n",
       "permno               0.024\n",
       "ret                  0.016\n",
       "mom6m                0.010\n",
       "sz_cat               0.007\n",
       "mom3m                0.006"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = pd.DataFrame({'feature':x_cols,'importance':np.round(dtree1.feature_importances_,3)})\n",
    "importances = importances.sort_values('importance',ascending=False).set_index('feature')\n",
    "importances.head(10) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IDIwjhHu0pwt"
   },
   "source": [
    "### Random Forest Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "0HgsxWIM0u3w"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF = RandomForestClassifier(n_estimators = 100, criterion = 'gini', max_depth = 7, min_samples_split = 125)\n",
    "RF1 = RF.fit(x_train, y_train1)\n",
    "RF2 = RF.fit(x_train, y_train2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors (KNN) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn1 = knn.fit(x_train, y_train1)\n",
    "knn2 = knn.fit(x_train, y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Discriminant Analysis (LDA) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "lda_svd = LinearDiscriminantAnalysis()\n",
    "\n",
    "lda1 = lda.fit(x_train, y_train1)\n",
    "lda_svd1 = lda_svd.fit(x_train, y_train1)\n",
    "\n",
    "lda2 = lda.fit(x_train, y_train2)\n",
    "lda_svd2 = lda_svd.fit(x_train, y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadratic Discriminant Analysis (QDA) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda1 = qda.fit(x_train, y_train1)\n",
    "qda2 = qda.fit(x_train, y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes (Gaussian) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb1 = gnb.fit(x_train, y_train1)\n",
    "gnb2 = gnb.fit(x_train, y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfIgVY-urQn7"
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7uMJN_5cwDqm"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N4pcJQt2qlJ_",
    "outputId": "d999f7f1-212b-4e5e-b478-1992e697f515"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09903438117393998"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.49509591891607535"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.09316617674914586"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.49693772318140045"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in-sample (train set) accuracy # higher #0.13038192211921767\n",
    "mlr_tgt1.score(x_train, y_train1) \n",
    "mlr_tgt2.score(x_train, y_train2)\n",
    "\n",
    "# out-of-sample (test set) accuracy #0.1257642533989549\n",
    "mlr_tgt1.score(x_test, y_test1) \n",
    "mlr_tgt2.score(x_test, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXn5hyVswHhS"
   },
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x2D4vkQbwKR9",
    "outputId": "05fdadcf-a7a1-48b8-ca61-23fa87d2a60c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09693012707356706"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.49951485252685845"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.09976778611066289"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.5025571589928511"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree1.score(x_train, y_train1) #0.1301189 \n",
    "dtree2.score(x_train, y_train2) #0.1301189 \n",
    "dtree1.score(x_test, y_test1) #0.12926\n",
    "dtree2.score(x_test, y_test2) #0.12926"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X0obMyOK1Cs3"
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zEVzNhJv1GzE",
    "outputId": "3fcc2761-f51b-42a1-fe20-dc0bee0fae8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09814007318128148"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.510036123028723"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.09875053493380852"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.504865266835507"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF1.score(x_train, y_train1) #0.1301189 \n",
    "RF2.score(x_train, y_train2) #0.1301189 \n",
    "RF1.score(x_test, y_test1) #0.12926\n",
    "RF2.score(x_test, y_test2) #0.12926"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07146865245905472"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.6404238902982196"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.05231477259174553"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.4344855164478992"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn1.score(x_train, y_train1)\n",
    "knn2.score(x_train, y_train2)\n",
    "knn1.score(x_test, y_test1)\n",
    "knn2.score(x_test, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0988298009141815"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.09897008452087303"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.49486211290492277"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.49504915771384483"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.09329947173094057"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.09357307721988761"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.49723237524642033"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.4974358254817912"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda1.score(x_train, y_train1)\n",
    "lda_svd1.score(x_train, y_train1)\n",
    "lda2.score(x_train, y_train2)\n",
    "lda_svd2.score(x_train, y_train2)\n",
    "\n",
    "lda1.score(x_test, y_test1)\n",
    "lda_svd1.score(x_test, y_test1)\n",
    "lda2.score(x_test, y_test2)\n",
    "lda_svd2.score(x_test, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09231830350358308"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.48761997170947263"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.09184024245655636"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.48149655186928675"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qda1.score(x_train, y_train1)\n",
    "qda2.score(x_train, y_train2)\n",
    "qda1.score(x_test, y_test1)\n",
    "qda2.score(x_test, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09113758314726271"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.4887539308635625"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.08959527434211911"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.48038809886278333"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb1.score(x_train, y_train1)\n",
    "gnb2.score(x_train, y_train2)\n",
    "gnb1.score(x_test, y_test1)\n",
    "gnb2.score(x_test, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kIt02RcDrOJ6"
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5mz3muvwWEI"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S7V7bB8Pq2PV",
    "outputId": "785faa62-6c20-43d4-bab2-2cbbf30e1635"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09316617674914586"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.49693772318140045"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict\n",
    "MLR1_y_pred1 = mlr_tgt1.predict(x_test)\n",
    "MLR2_y_pred2 = mlr_tgt2.predict(x_test)\n",
    "\n",
    "# Prediction accuracy (compare with the test set accuracy above) #0.1257642533989549\n",
    "metrics.accuracy_score(y_test1, MLR1_y_pred1)\n",
    "metrics.accuracy_score(y_test2, MLR2_y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PetkkDcCwZoc"
   },
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jb2hvlhYwcSR",
    "outputId": "8a492c20-485c-49e5-cccd-f4a0f6c5c4b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09976778611066289"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.5025571589928511"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DR1_y_pred1 = dtree1.predict(x_test)\n",
    "DR2_y_pred2 = dtree2.predict(x_test)\n",
    "# Prediction accuracy\n",
    "metrics.accuracy_score(y_test1, DR1_y_pred1) #0.12926105 - same as out of sample\n",
    "metrics.accuracy_score(y_test2, DR2_y_pred2) #0.12926105 - same as out of sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OAWF0TOJ1Q2k"
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uRNybynV1TRC",
    "outputId": "7ce111cd-4e7e-4ddf-bdf7-6446d2254576"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09875053493380852"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.504865266835507"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF1_y_pred1 = RF1.predict(x_test)\n",
    "RF2_y_pred2 = RF2.predict(x_test)\n",
    "# Prediction accuracy\n",
    "metrics.accuracy_score(y_test1, RF1_y_pred1) #0.12926105 - same as out of sample\n",
    "metrics.accuracy_score(y_test2, RF2_y_pred2) #0.12926105 - same as out of sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05231477259174553"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.4344855164478992"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn1_y_pred1 = knn1.predict(x_test)\n",
    "knn2_y_pred2 = knn2.predict(x_test)\n",
    "\n",
    "metrics.accuracy_score(y_test1, knn1_y_pred1)\n",
    "metrics.accuracy_score(y_test2, knn2_y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09329947173094057"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.09357307721988761"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.49723237524642033"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.4974358254817912"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda1_y_pred1 = lda1.predict(x_test)\n",
    "lda_svd1_y_pred1 = lda_svd1.predict(x_test)\n",
    "\n",
    "lda2_y_pred2 = lda2.predict(x_test)\n",
    "lda_svd2_y_pred2 = lda_svd2.predict(x_test)\n",
    "\n",
    "metrics.accuracy_score(y_test1, lda1_y_pred1)\n",
    "metrics.accuracy_score(y_test1, lda_svd1_y_pred1)\n",
    "\n",
    "metrics.accuracy_score(y_test2, lda2_y_pred2)\n",
    "metrics.accuracy_score(y_test2, lda_svd2_y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09184024245655636"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.48149655186928675"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qda1_y_pred1 = qda1.predict(x_test)\n",
    "metrics.accuracy_score(y_test1, qda1_y_pred1)\n",
    "\n",
    "qda2_y_pred2 = qda2.predict(x_test)\n",
    "metrics.accuracy_score(y_test2, qda2_y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08959527434211911"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.48038809886278333"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb1_y_pred1 = gnb1.predict(x_test)\n",
    "metrics.accuracy_score(y_test1, gnb1_y_pred1)\n",
    "\n",
    "gnb2_y_pred2 = gnb2.predict(x_test)\n",
    "metrics.accuracy_score(y_test2, gnb2_y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rxban1Qcsx2o"
   },
   "source": [
    "## Hyperparameter Tuning and fitting best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cp6tyYpzwzp5"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FKRMQ8gsrbUo",
    "outputId": "d11f3d87-395e-4a4b-f883-3669fbf09c61"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  30 | elapsed:    6.0s remaining:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  30 | elapsed:    9.0s remaining:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  30 | elapsed:    9.2s remaining:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  30 | elapsed:    9.8s remaining:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:   11.2s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   11.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  30 | elapsed:    2.8s remaining:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  30 | elapsed:    3.4s remaining:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  30 | elapsed:    4.5s remaining:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  30 | elapsed:    4.8s remaining:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:    5.2s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    5.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.12636624, 0.12648314, 0.12935469, 0.12941314, 0.12730886,\n",
       "       0.12678279, 0.12877017, 0.12707505, 0.12643208, 0.13221884,\n",
       "       0.1257233 , 0.12221638, 0.13023147, 0.12602291, 0.12847791,\n",
       "       0.12783493, 0.13233575, 0.1323942 , 0.12485387, 0.1322773 ,\n",
       "       0.1284704 , 0.12905488, 0.12818564, 0.13110825, 0.13069909,\n",
       "       0.13011457, 0.12707505, 0.12462006, 0.1255553 , 0.12748422])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.49634695, 0.49383365, 0.49567454, 0.49433014, 0.49421323,\n",
       "       0.49321955, 0.49468085, 0.49637596, 0.49713584, 0.49403788,\n",
       "       0.49833421, 0.49827576, 0.49497311, 0.49187515, 0.49584989,\n",
       "       0.49625906, 0.4907061 , 0.49386252, 0.49643442, 0.4919336 ,\n",
       "       0.49634695, 0.49196329, 0.49380407, 0.49579144, 0.49649287,\n",
       "       0.49275193, 0.49450549, 0.49713584, 0.49620061, 0.49485621])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=0)\n",
    "n_scores1 = cross_val_score(mlr_tgt1, x_train, y_train1, scoring='accuracy', cv=cv, n_jobs=-1, verbose = 10)\n",
    "n_scores2 = cross_val_score(mlr_tgt2, x_train, y_train2, scoring='accuracy', cv=cv, n_jobs=-1, verbose = 10)\n",
    "n_scores1\n",
    "n_scores2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "1UjVHcHgro3p"
   },
   "outputs": [],
   "source": [
    "# Create regularization penalty space\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Create regularization hyperparameter space\n",
    "C = np.logspace(0, 4, 10)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C, penalty=penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "A4q0UWMqsPpi"
   },
   "outputs": [],
   "source": [
    "MLR1_grid = GridSearchCV(mlr_tgt1, hyperparameters, cv=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WNJ8luUFsdYM",
    "outputId": "f18ab70c-3234-4961-9630-303cc3bbcce9",
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.12748857        nan 0.12750611        nan 0.12751195\n",
      "        nan 0.12751195        nan 0.12751195        nan 0.12751195\n",
      "        nan 0.12751195        nan 0.12751195        nan 0.12751195\n",
      "        nan 0.12751195]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "MLR1_BR_fit = MLR1_grid.fit(x_train, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "2-s5HO-0w6oh"
   },
   "outputs": [],
   "source": [
    "MLR2_grid = GridSearchCV(mlr_tgt2, hyperparameters, cv=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wHEgx3muxBMU",
    "outputId": "33798928-a4dd-437f-965f-bdfc7598c6ff",
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.49456986        nan 0.4945757         nan 0.4945757\n",
      "        nan 0.4945757         nan 0.4945757         nan 0.4945757\n",
      "        nan 0.4945757         nan 0.4945757         nan 0.4945757\n",
      "        nan 0.4945757 ]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "MLR2_BR_fit = MLR2_grid.fit(x_train, y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8t9NZ-Ixc4U"
   },
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fiCqqZ6Xxr8b",
    "outputId": "9da4f457-4be1-4de7-de5f-e96e4489e5d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[CV] END ..criterion=gini, max_depth=5, min_samples_split=50; total time=   0.5s\n",
      "[CV] END ..criterion=gini, max_depth=5, min_samples_split=50; total time=   0.5s\n",
      "[CV] END ..criterion=gini, max_depth=5, min_samples_split=50; total time=   0.5s\n",
      "[CV] END ..criterion=gini, max_depth=5, min_samples_split=75; total time=   0.5s\n",
      "[CV] END ..criterion=gini, max_depth=5, min_samples_split=75; total time=   0.5s\n",
      "[CV] END ..criterion=gini, max_depth=5, min_samples_split=75; total time=   0.5s\n",
      "[CV] END .criterion=gini, max_depth=5, min_samples_split=100; total time=   0.5s\n",
      "[CV] END .criterion=gini, max_depth=5, min_samples_split=100; total time=   0.5s\n",
      "[CV] END .criterion=gini, max_depth=5, min_samples_split=100; total time=   0.5s\n",
      "[CV] END .criterion=gini, max_depth=5, min_samples_split=125; total time=   0.5s\n",
      "[CV] END .criterion=gini, max_depth=5, min_samples_split=125; total time=   0.5s\n",
      "[CV] END .criterion=gini, max_depth=5, min_samples_split=125; total time=   0.6s\n",
      "[CV] END .criterion=gini, max_depth=10, min_samples_split=50; total time=   1.0s\n",
      "[CV] END .criterion=gini, max_depth=10, min_samples_split=50; total time=   0.9s\n",
      "[CV] END .criterion=gini, max_depth=10, min_samples_split=50; total time=   0.9s\n",
      "[CV] END .criterion=gini, max_depth=10, min_samples_split=75; total time=   0.9s\n",
      "[CV] END .criterion=gini, max_depth=10, min_samples_split=75; total time=   0.9s\n",
      "[CV] END .criterion=gini, max_depth=10, min_samples_split=75; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=100; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=100; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=100; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=125; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=125; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=125; total time=   1.0s\n",
      "[CV] END .criterion=gini, max_depth=15, min_samples_split=50; total time=   1.2s\n",
      "[CV] END .criterion=gini, max_depth=15, min_samples_split=50; total time=   1.2s\n",
      "[CV] END .criterion=gini, max_depth=15, min_samples_split=50; total time=   1.2s\n",
      "[CV] END .criterion=gini, max_depth=15, min_samples_split=75; total time=   1.2s\n",
      "[CV] END .criterion=gini, max_depth=15, min_samples_split=75; total time=   1.2s\n",
      "[CV] END .criterion=gini, max_depth=15, min_samples_split=75; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_split=100; total time=   1.3s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_split=100; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_split=100; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_split=125; total time=   1.3s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_split=125; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_split=125; total time=   1.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=50; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=50; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=50; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=75; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=75; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=75; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=100; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=100; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=100; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=125; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=125; total time=   1.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=125; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=50; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=50; total time=   2.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=50; total time=   2.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=75; total time=   2.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=75; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=75; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=100; total time=   2.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=100; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=100; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=125; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=125; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=125; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_split=50; total time=   2.7s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_split=50; total time=   2.5s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_split=50; total time=   2.5s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_split=75; total time=   2.5s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_split=75; total time=   2.4s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_split=75; total time=   2.4s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_split=100; total time=   2.4s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_split=100; total time=   2.4s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_split=100; total time=   2.4s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_split=125; total time=   2.4s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_split=125; total time=   2.3s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_split=125; total time=   2.4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=DecisionTreeClassifier(max_depth=5),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [5, 10, 15],\n",
       "                         'min_samples_split': [50, 75, 100, 125]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters to test\n",
    "param_grid = {'criterion': ['gini','entropy'],'max_depth': [5,10,15], 'min_samples_split': [50, 75, 100, 125]}\n",
    "\n",
    "DR1_grid = GridSearchCV(dtree1, param_grid, cv=3, verbose = 2)\n",
    "DR1_grid.fit(x_train, y_train1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jo46pcAqyfVq",
    "outputId": "c7059723-bc2c-4537-e8cf-023b79679a5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=50 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_depth=5, min_samples_split=50, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=50 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_depth=5, min_samples_split=50, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=50 ...............\n",
      "[CV]  criterion=gini, max_depth=5, min_samples_split=50, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=75 ...............\n",
      "[CV]  criterion=gini, max_depth=5, min_samples_split=75, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=75 ...............\n",
      "[CV]  criterion=gini, max_depth=5, min_samples_split=75, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=75 ...............\n",
      "[CV]  criterion=gini, max_depth=5, min_samples_split=75, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=100 ..............\n",
      "[CV]  criterion=gini, max_depth=5, min_samples_split=100, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=100 ..............\n",
      "[CV]  criterion=gini, max_depth=5, min_samples_split=100, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=100 ..............\n",
      "[CV]  criterion=gini, max_depth=5, min_samples_split=100, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=125 ..............\n",
      "[CV]  criterion=gini, max_depth=5, min_samples_split=125, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=125 ..............\n",
      "[CV]  criterion=gini, max_depth=5, min_samples_split=125, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=125 ..............\n",
      "[CV]  criterion=gini, max_depth=5, min_samples_split=125, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_split=50 ..............\n",
      "[CV]  criterion=gini, max_depth=10, min_samples_split=50, total=   0.5s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_split=50 ..............\n",
      "[CV]  criterion=gini, max_depth=10, min_samples_split=50, total=   0.5s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_split=50 ..............\n",
      "[CV]  criterion=gini, max_depth=10, min_samples_split=50, total=   0.5s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_split=75 ..............\n",
      "[CV]  criterion=gini, max_depth=10, min_samples_split=75, total=   0.6s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_split=75 ..............\n",
      "[CV]  criterion=gini, max_depth=10, min_samples_split=75, total=   0.5s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_split=75 ..............\n",
      "[CV]  criterion=gini, max_depth=10, min_samples_split=75, total=   0.5s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_split=100 .............\n",
      "[CV]  criterion=gini, max_depth=10, min_samples_split=100, total=   0.5s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_split=100 .............\n",
      "[CV]  criterion=gini, max_depth=10, min_samples_split=100, total=   0.5s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_split=100 .............\n",
      "[CV]  criterion=gini, max_depth=10, min_samples_split=100, total=   0.5s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_split=125 .............\n",
      "[CV]  criterion=gini, max_depth=10, min_samples_split=125, total=   0.5s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_split=125 .............\n",
      "[CV]  criterion=gini, max_depth=10, min_samples_split=125, total=   0.5s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_split=125 .............\n",
      "[CV]  criterion=gini, max_depth=10, min_samples_split=125, total=   0.5s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_split=50 ..............\n",
      "[CV]  criterion=gini, max_depth=15, min_samples_split=50, total=   0.7s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_split=50 ..............\n",
      "[CV]  criterion=gini, max_depth=15, min_samples_split=50, total=   0.7s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_split=50 ..............\n",
      "[CV]  criterion=gini, max_depth=15, min_samples_split=50, total=   0.7s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_split=75 ..............\n",
      "[CV]  criterion=gini, max_depth=15, min_samples_split=75, total=   0.7s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_split=75 ..............\n",
      "[CV]  criterion=gini, max_depth=15, min_samples_split=75, total=   0.7s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_split=75 ..............\n",
      "[CV]  criterion=gini, max_depth=15, min_samples_split=75, total=   0.7s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_split=100 .............\n",
      "[CV]  criterion=gini, max_depth=15, min_samples_split=100, total=   0.7s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_split=100 .............\n",
      "[CV]  criterion=gini, max_depth=15, min_samples_split=100, total=   0.7s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_split=100 .............\n",
      "[CV]  criterion=gini, max_depth=15, min_samples_split=100, total=   0.7s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_split=125 .............\n",
      "[CV]  criterion=gini, max_depth=15, min_samples_split=125, total=   0.7s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_split=125 .............\n",
      "[CV]  criterion=gini, max_depth=15, min_samples_split=125, total=   0.7s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_split=125 .............\n",
      "[CV]  criterion=gini, max_depth=15, min_samples_split=125, total=   0.7s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=50 ............\n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=50, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=50 ............\n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=50, total=   0.6s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=50 ............\n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=50, total=   0.4s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=75 ............\n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=75, total=   0.4s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=75 ............\n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=75, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=75 ............\n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=75, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=100 ...........\n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=100, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=100 ...........\n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=100, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=100 ...........\n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=100, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=125 ...........\n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=125, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=125 ...........\n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=125, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=125 ...........\n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=125, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_split=50 ...........\n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_split=50, total=   0.9s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_split=50 ...........\n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_split=50, total=   1.0s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_split=50 ...........\n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_split=50, total=   1.0s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_split=75 ...........\n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_split=75, total=   1.0s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_split=75 ...........\n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_split=75, total=   1.0s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_split=75 ...........\n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_split=75, total=   1.0s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_split=100 ..........\n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_split=100, total=   0.9s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_split=100 ..........\n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_split=100, total=   0.9s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_split=100 ..........\n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_split=100, total=   0.9s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_split=125 ..........\n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_split=125, total=   0.9s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_split=125 ..........\n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_split=125, total=   0.9s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_split=125 ..........\n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_split=125, total=   0.8s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_split=50 ...........\n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_split=50, total=   1.3s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_split=50 ...........\n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_split=50, total=   1.3s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_split=50 ...........\n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_split=50, total=   1.3s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_split=75 ...........\n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_split=75, total=   1.3s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_split=75 ...........\n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_split=75, total=   1.3s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_split=75 ...........\n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_split=75, total=   1.3s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_split=100 ..........\n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_split=100, total=   1.3s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_split=100 ..........\n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_split=100, total=   1.3s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_split=100 ..........\n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_split=100, total=   1.4s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_split=125 ..........\n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_split=125, total=   1.3s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_split=125 ..........\n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_split=125, total=   1.2s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_split=125 ..........\n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_split=125, total=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed:   50.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                              criterion='gini', max_depth=2,\n",
       "                                              max_features='log2',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort='deprecated',\n",
       "                                              random_state=None,\n",
       "                                              splitter='best'),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [5, 10, 15],\n",
       "                         'min_samples_split': [50, 75, 100, 125]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=2)"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters to test\n",
    "param_grid = {'criterion': ['gini','entropy'],'max_depth': [5,10,15], 'min_samples_split': [50, 75, 100, 125]}\n",
    "\n",
    "DR2_grid = GridSearchCV(dtree2, param_grid, cv=3, verbose = 2)\n",
    "DR2_grid.fit(x_train, y_train2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kg2eFoIs1ecR"
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pRXa70BE1iNT",
    "outputId": "0e4a7156-c026-4049-a9cb-f559bc09327f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=75, n_estimators=75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_depth=5, min_samples_split=75, n_estimators=75, score=0.113, total=  11.3s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=75, n_estimators=75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_depth=5, min_samples_split=75, n_estimators=75, score=0.133, total=  11.1s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=75, n_estimators=75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   22.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_depth=5, min_samples_split=75, n_estimators=75, score=0.069, total=  11.2s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=75, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   33.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_depth=5, min_samples_split=75, n_estimators=100, score=0.113, total=  15.0s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=75, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   48.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_depth=5, min_samples_split=75, n_estimators=100, score=0.133, total=  15.3s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=75, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_depth=5, min_samples_split=75, n_estimators=100, score=0.069, total=  15.4s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=75, n_estimators=150 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  1.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_depth=5, min_samples_split=75, n_estimators=150, score=0.113, total=  23.3s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=75, n_estimators=150 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  1.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_depth=5, min_samples_split=75, n_estimators=150, score=0.133, total=  23.3s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=75, n_estimators=150 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  2.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_depth=5, min_samples_split=75, n_estimators=150, score=0.068, total=  22.6s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=125, n_estimators=75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  2.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_depth=5, min_samples_split=125, n_estimators=75, score=0.113, total=  11.3s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=125, n_estimators=75 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_split=125, n_estimators=75, score=0.132, total=  11.1s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=125, n_estimators=75 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_split=125, n_estimators=75, score=0.070, total=  11.4s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=125, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_split=125, n_estimators=100, score=0.113, total=  15.3s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=125, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_split=125, n_estimators=100, score=0.134, total=  14.9s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=125, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_split=125, n_estimators=100, score=0.073, total=  14.6s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=125, n_estimators=150 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_split=125, n_estimators=150, score=0.113, total=  22.9s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=125, n_estimators=150 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_split=125, n_estimators=150, score=0.133, total=  23.2s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=125, n_estimators=150 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_split=125, n_estimators=150, score=0.071, total=  23.6s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=175, n_estimators=75 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_split=175, n_estimators=75, score=0.113, total=  11.8s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=175, n_estimators=75 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_split=175, n_estimators=75, score=0.133, total=  11.7s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=175, n_estimators=75 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_split=175, n_estimators=75, score=0.074, total=  11.6s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=175, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_split=175, n_estimators=100, score=0.113, total=  15.4s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=175, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_split=175, n_estimators=100, score=0.133, total=  14.9s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=175, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_split=175, n_estimators=100, score=0.074, total=  15.4s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=175, n_estimators=150 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_split=175, n_estimators=150, score=0.113, total=  23.0s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=175, n_estimators=150 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_split=175, n_estimators=150, score=0.133, total=  22.7s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_split=175, n_estimators=150 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_split=175, n_estimators=150, score=0.073, total=  22.9s\n",
      "[CV] criterion=gini, max_depth=7, min_samples_split=75, n_estimators=75 \n",
      "[CV]  criterion=gini, max_depth=7, min_samples_split=75, n_estimators=75, score=0.113, total=  14.0s\n",
      "[CV] criterion=gini, max_depth=7, min_samples_split=75, n_estimators=75 \n",
      "[CV]  criterion=gini, max_depth=7, min_samples_split=75, n_estimators=75, score=0.134, total=  14.2s\n",
      "[CV] criterion=gini, max_depth=7, min_samples_split=75, n_estimators=75 \n",
      "[CV]  criterion=gini, max_depth=7, min_samples_split=75, n_estimators=75, score=0.069, total=  14.5s\n",
      "[CV] criterion=gini, max_depth=7, min_samples_split=75, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=7, min_samples_split=75, n_estimators=100, score=0.113, total=  19.2s\n",
      "[CV] criterion=gini, max_depth=7, min_samples_split=75, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=7, min_samples_split=75, n_estimators=100, score=0.136, total=  20.0s\n",
      "[CV] criterion=gini, max_depth=7, min_samples_split=75, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=7, min_samples_split=75, n_estimators=100, score=0.070, total=  21.2s\n",
      "[CV] criterion=gini, max_depth=7, min_samples_split=75, n_estimators=150 \n",
      "[CV]  criterion=gini, max_depth=7, min_samples_split=75, n_estimators=150, score=0.113, total=  31.3s\n",
      "[CV] criterion=gini, max_depth=7, min_samples_split=75, n_estimators=150 \n",
      "[CV]  criterion=gini, max_depth=7, min_samples_split=75, n_estimators=150, score=0.135, total=  29.9s\n",
      "[CV] criterion=gini, max_depth=7, min_samples_split=75, n_estimators=150 \n",
      "[CV]  criterion=gini, max_depth=7, min_samples_split=75, n_estimators=150, score=0.070, total=  29.6s\n",
      "[CV] criterion=gini, max_depth=7, min_samples_split=125, n_estimators=75 \n",
      "[CV]  criterion=gini, max_depth=7, min_samples_split=125, n_estimators=75, score=0.113, total=  14.9s\n",
      "[CV] criterion=gini, max_depth=7, min_samples_split=125, n_estimators=75 \n",
      "[CV]  criterion=gini, max_depth=7, min_samples_split=125, n_estimators=75, score=0.133, total=  14.4s\n",
      "[CV] criterion=gini, max_depth=7, min_samples_split=125, n_estimators=75 \n",
      "[CV]  criterion=gini, max_depth=7, min_samples_split=125, n_estimators=75, score=0.069, total=  15.0s\n",
      "[CV] criterion=gini, max_depth=7, min_samples_split=125, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=7, min_samples_split=125, n_estimators=100, score=0.113, total=  19.8s\n",
      "[CV] criterion=gini, max_depth=7, min_samples_split=125, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=7, min_samples_split=125, n_estimators=100, score=0.134, total=  19.6s\n",
      "[CV] criterion=gini, max_depth=7, min_samples_split=125, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=7, min_samples_split=125, n_estimators=100, score=0.071, total=  19.6s\n",
      "[CV] criterion=gini, max_depth=7, min_samples_split=125, n_estimators=150 \n",
      "[CV]  criterion=gini, max_depth=7, min_samples_split=125, n_estimators=150, score=0.113, total=  29.9s\n",
      "[CV] criterion=gini, max_depth=7, min_samples_split=125, n_estimators=150 \n",
      "[CV]  criterion=gini, max_depth=7, min_samples_split=125, n_estimators=150, score=0.134, total=  29.6s\n",
      "[CV] criterion=gini, max_depth=7, min_samples_split=125, n_estimators=150 \n",
      "[CV]  criterion=gini, max_depth=7, min_samples_split=125, n_estimators=150, score=0.071, total=  30.0s\n",
      "[CV] criterion=gini, max_depth=7, min_samples_split=175, n_estimators=75 \n",
      "[CV]  criterion=gini, max_depth=7, min_samples_split=175, n_estimators=75, score=0.113, total=  14.4s\n",
      "[CV] criterion=gini, max_depth=7, min_samples_split=175, n_estimators=75 \n",
      "[CV]  criterion=gini, max_depth=7, min_samples_split=175, n_estimators=75, score=0.134, total=  14.2s\n",
      "[CV] criterion=gini, max_depth=7, min_samples_split=175, n_estimators=75 \n",
      "[CV]  criterion=gini, max_depth=7, min_samples_split=175, n_estimators=75, score=0.071, total=  15.1s\n",
      "[CV] criterion=gini, max_depth=7, min_samples_split=175, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=7, min_samples_split=175, n_estimators=100, score=0.113, total=  20.2s\n",
      "[CV] criterion=gini, max_depth=7, min_samples_split=175, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=7, min_samples_split=175, n_estimators=100, score=0.135, total=  19.3s\n",
      "[CV] criterion=gini, max_depth=7, min_samples_split=175, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=7, min_samples_split=175, n_estimators=100, score=0.072, total=  19.2s\n",
      "[CV] criterion=gini, max_depth=7, min_samples_split=175, n_estimators=150 \n",
      "[CV]  criterion=gini, max_depth=7, min_samples_split=175, n_estimators=150, score=0.113, total=  28.7s\n",
      "[CV] criterion=gini, max_depth=7, min_samples_split=175, n_estimators=150 \n",
      "[CV]  criterion=gini, max_depth=7, min_samples_split=175, n_estimators=150, score=0.135, total=  28.3s\n",
      "[CV] criterion=gini, max_depth=7, min_samples_split=175, n_estimators=150 \n",
      "[CV]  criterion=gini, max_depth=7, min_samples_split=175, n_estimators=150, score=0.072, total=  28.8s\n",
      "[CV] criterion=gini, max_depth=8, min_samples_split=75, n_estimators=75 \n",
      "[CV]  criterion=gini, max_depth=8, min_samples_split=75, n_estimators=75, score=0.113, total=  15.6s\n",
      "[CV] criterion=gini, max_depth=8, min_samples_split=75, n_estimators=75 \n",
      "[CV]  criterion=gini, max_depth=8, min_samples_split=75, n_estimators=75, score=0.134, total=  15.4s\n",
      "[CV] criterion=gini, max_depth=8, min_samples_split=75, n_estimators=75 \n",
      "[CV]  criterion=gini, max_depth=8, min_samples_split=75, n_estimators=75, score=0.069, total=  15.6s\n",
      "[CV] criterion=gini, max_depth=8, min_samples_split=75, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=8, min_samples_split=75, n_estimators=100, score=0.113, total=  20.5s\n",
      "[CV] criterion=gini, max_depth=8, min_samples_split=75, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=8, min_samples_split=75, n_estimators=100, score=0.136, total=  20.9s\n",
      "[CV] criterion=gini, max_depth=8, min_samples_split=75, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=8, min_samples_split=75, n_estimators=100, score=0.071, total=  20.8s\n",
      "[CV] criterion=gini, max_depth=8, min_samples_split=75, n_estimators=150 \n",
      "[CV]  criterion=gini, max_depth=8, min_samples_split=75, n_estimators=150, score=0.113, total=  31.6s\n",
      "[CV] criterion=gini, max_depth=8, min_samples_split=75, n_estimators=150 \n",
      "[CV]  criterion=gini, max_depth=8, min_samples_split=75, n_estimators=150, score=0.135, total=  30.9s\n",
      "[CV] criterion=gini, max_depth=8, min_samples_split=75, n_estimators=150 \n",
      "[CV]  criterion=gini, max_depth=8, min_samples_split=75, n_estimators=150, score=0.070, total=  31.3s\n",
      "[CV] criterion=gini, max_depth=8, min_samples_split=125, n_estimators=75 \n",
      "[CV]  criterion=gini, max_depth=8, min_samples_split=125, n_estimators=75, score=0.113, total=  15.5s\n",
      "[CV] criterion=gini, max_depth=8, min_samples_split=125, n_estimators=75 \n",
      "[CV]  criterion=gini, max_depth=8, min_samples_split=125, n_estimators=75, score=0.134, total=  15.6s\n",
      "[CV] criterion=gini, max_depth=8, min_samples_split=125, n_estimators=75 \n",
      "[CV]  criterion=gini, max_depth=8, min_samples_split=125, n_estimators=75, score=0.072, total=  15.7s\n",
      "[CV] criterion=gini, max_depth=8, min_samples_split=125, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=8, min_samples_split=125, n_estimators=100, score=0.113, total=  21.5s\n",
      "[CV] criterion=gini, max_depth=8, min_samples_split=125, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=8, min_samples_split=125, n_estimators=100, score=0.136, total=  21.5s\n",
      "[CV] criterion=gini, max_depth=8, min_samples_split=125, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=8, min_samples_split=125, n_estimators=100, score=0.070, total=  21.4s\n",
      "[CV] criterion=gini, max_depth=8, min_samples_split=125, n_estimators=150 \n",
      "[CV]  criterion=gini, max_depth=8, min_samples_split=125, n_estimators=150, score=0.113, total=  31.8s\n",
      "[CV] criterion=gini, max_depth=8, min_samples_split=125, n_estimators=150 \n",
      "[CV]  criterion=gini, max_depth=8, min_samples_split=125, n_estimators=150, score=0.134, total=  31.8s\n",
      "[CV] criterion=gini, max_depth=8, min_samples_split=125, n_estimators=150 \n",
      "[CV]  criterion=gini, max_depth=8, min_samples_split=125, n_estimators=150, score=0.068, total=  31.1s\n",
      "[CV] criterion=gini, max_depth=8, min_samples_split=175, n_estimators=75 \n",
      "[CV]  criterion=gini, max_depth=8, min_samples_split=175, n_estimators=75, score=0.113, total=  15.7s\n",
      "[CV] criterion=gini, max_depth=8, min_samples_split=175, n_estimators=75 \n",
      "[CV]  criterion=gini, max_depth=8, min_samples_split=175, n_estimators=75, score=0.135, total=  15.2s\n",
      "[CV] criterion=gini, max_depth=8, min_samples_split=175, n_estimators=75 \n",
      "[CV]  criterion=gini, max_depth=8, min_samples_split=175, n_estimators=75, score=0.073, total=  15.9s\n",
      "[CV] criterion=gini, max_depth=8, min_samples_split=175, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=8, min_samples_split=175, n_estimators=100, score=0.113, total=  21.2s\n",
      "[CV] criterion=gini, max_depth=8, min_samples_split=175, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=8, min_samples_split=175, n_estimators=100, score=0.135, total=  20.8s\n",
      "[CV] criterion=gini, max_depth=8, min_samples_split=175, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=8, min_samples_split=175, n_estimators=100, score=0.071, total=  20.7s\n",
      "[CV] criterion=gini, max_depth=8, min_samples_split=175, n_estimators=150 \n",
      "[CV]  criterion=gini, max_depth=8, min_samples_split=175, n_estimators=150, score=0.113, total=  31.2s\n",
      "[CV] criterion=gini, max_depth=8, min_samples_split=175, n_estimators=150 \n",
      "[CV]  criterion=gini, max_depth=8, min_samples_split=175, n_estimators=150, score=0.135, total=  31.3s\n",
      "[CV] criterion=gini, max_depth=8, min_samples_split=175, n_estimators=150 \n",
      "[CV]  criterion=gini, max_depth=8, min_samples_split=175, n_estimators=150, score=0.071, total=  31.4s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=75, n_estimators=75 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=75, n_estimators=75, score=0.113, total=  30.6s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=75, n_estimators=75 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=75, n_estimators=75, score=0.134, total=  30.5s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=75, n_estimators=75 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=75, n_estimators=75, score=0.074, total=  29.9s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=75, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=75, n_estimators=100, score=0.113, total=  40.1s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=75, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=75, n_estimators=100, score=0.132, total=  40.1s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=75, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=75, n_estimators=100, score=0.073, total=  40.3s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=75, n_estimators=150 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=75, n_estimators=150, score=0.113, total= 1.0min\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=75, n_estimators=150 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=75, n_estimators=150, score=0.133, total= 1.0min\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=75, n_estimators=150 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=75, n_estimators=150, score=0.074, total=  59.7s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=125, n_estimators=75 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=125, n_estimators=75, score=0.113, total=  30.6s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=125, n_estimators=75 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=125, n_estimators=75, score=0.132, total=  30.9s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=125, n_estimators=75 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=125, n_estimators=75, score=0.075, total=  31.2s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=125, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=125, n_estimators=100, score=0.113, total=  41.4s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=125, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=125, n_estimators=100, score=0.132, total=  41.2s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=125, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=125, n_estimators=100, score=0.074, total=  41.3s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=125, n_estimators=150 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=125, n_estimators=150, score=0.113, total= 1.0min\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=125, n_estimators=150 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=125, n_estimators=150, score=0.133, total= 1.0min\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=125, n_estimators=150 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=125, n_estimators=150, score=0.072, total= 1.0min\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=175, n_estimators=75 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=175, n_estimators=75, score=0.113, total=  31.1s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=175, n_estimators=75 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=175, n_estimators=75, score=0.132, total=  31.8s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=175, n_estimators=75 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=175, n_estimators=75, score=0.074, total=  31.3s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=175, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=175, n_estimators=100, score=0.113, total=  41.0s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=175, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=175, n_estimators=100, score=0.132, total=  39.5s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=175, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=175, n_estimators=100, score=0.073, total=  39.6s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=175, n_estimators=150 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=175, n_estimators=150, score=0.113, total=  59.6s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=175, n_estimators=150 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=175, n_estimators=150, score=0.133, total=  59.7s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_split=175, n_estimators=150 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_split=175, n_estimators=150, score=0.074, total=  58.5s\n",
      "[CV] criterion=entropy, max_depth=7, min_samples_split=75, n_estimators=75 \n",
      "[CV]  criterion=entropy, max_depth=7, min_samples_split=75, n_estimators=75, score=0.113, total=  42.2s\n",
      "[CV] criterion=entropy, max_depth=7, min_samples_split=75, n_estimators=75 \n",
      "[CV]  criterion=entropy, max_depth=7, min_samples_split=75, n_estimators=75, score=0.134, total=  42.5s\n",
      "[CV] criterion=entropy, max_depth=7, min_samples_split=75, n_estimators=75 \n",
      "[CV]  criterion=entropy, max_depth=7, min_samples_split=75, n_estimators=75, score=0.071, total=  40.9s\n",
      "[CV] criterion=entropy, max_depth=7, min_samples_split=75, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=7, min_samples_split=75, n_estimators=100, score=0.113, total=  56.8s\n",
      "[CV] criterion=entropy, max_depth=7, min_samples_split=75, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=7, min_samples_split=75, n_estimators=100, score=0.136, total=  56.8s\n",
      "[CV] criterion=entropy, max_depth=7, min_samples_split=75, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=7, min_samples_split=75, n_estimators=100, score=0.069, total=  54.7s\n",
      "[CV] criterion=entropy, max_depth=7, min_samples_split=75, n_estimators=150 \n",
      "[CV]  criterion=entropy, max_depth=7, min_samples_split=75, n_estimators=150, score=0.113, total= 1.3min\n",
      "[CV] criterion=entropy, max_depth=7, min_samples_split=75, n_estimators=150 \n",
      "[CV]  criterion=entropy, max_depth=7, min_samples_split=75, n_estimators=150, score=0.134, total= 1.4min\n",
      "[CV] criterion=entropy, max_depth=7, min_samples_split=75, n_estimators=150 \n",
      "[CV]  criterion=entropy, max_depth=7, min_samples_split=75, n_estimators=150, score=0.072, total= 1.4min\n",
      "[CV] criterion=entropy, max_depth=7, min_samples_split=125, n_estimators=75 \n",
      "[CV]  criterion=entropy, max_depth=7, min_samples_split=125, n_estimators=75, score=0.113, total=  40.3s\n",
      "[CV] criterion=entropy, max_depth=7, min_samples_split=125, n_estimators=75 \n",
      "[CV]  criterion=entropy, max_depth=7, min_samples_split=125, n_estimators=75, score=0.135, total=  40.9s\n",
      "[CV] criterion=entropy, max_depth=7, min_samples_split=125, n_estimators=75 \n",
      "[CV]  criterion=entropy, max_depth=7, min_samples_split=125, n_estimators=75, score=0.071, total=  41.0s\n",
      "[CV] criterion=entropy, max_depth=7, min_samples_split=125, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=7, min_samples_split=125, n_estimators=100, score=0.113, total=  55.2s\n",
      "[CV] criterion=entropy, max_depth=7, min_samples_split=125, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=7, min_samples_split=125, n_estimators=100, score=0.135, total=  55.3s\n",
      "[CV] criterion=entropy, max_depth=7, min_samples_split=125, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=7, min_samples_split=125, n_estimators=100, score=0.073, total=  53.8s\n",
      "[CV] criterion=entropy, max_depth=7, min_samples_split=125, n_estimators=150 \n",
      "[CV]  criterion=entropy, max_depth=7, min_samples_split=125, n_estimators=150, score=0.113, total= 1.4min\n",
      "[CV] criterion=entropy, max_depth=7, min_samples_split=125, n_estimators=150 \n",
      "[CV]  criterion=entropy, max_depth=7, min_samples_split=125, n_estimators=150, score=0.135, total= 1.4min\n",
      "[CV] criterion=entropy, max_depth=7, min_samples_split=125, n_estimators=150 \n",
      "[CV]  criterion=entropy, max_depth=7, min_samples_split=125, n_estimators=150, score=0.073, total= 1.3min\n",
      "[CV] criterion=entropy, max_depth=7, min_samples_split=175, n_estimators=75 \n",
      "[CV]  criterion=entropy, max_depth=7, min_samples_split=175, n_estimators=75, score=0.113, total=  41.0s\n",
      "[CV] criterion=entropy, max_depth=7, min_samples_split=175, n_estimators=75 \n",
      "[CV]  criterion=entropy, max_depth=7, min_samples_split=175, n_estimators=75, score=0.134, total=  40.6s\n",
      "[CV] criterion=entropy, max_depth=7, min_samples_split=175, n_estimators=75 \n",
      "[CV]  criterion=entropy, max_depth=7, min_samples_split=175, n_estimators=75, score=0.073, total=  41.5s\n",
      "[CV] criterion=entropy, max_depth=7, min_samples_split=175, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=7, min_samples_split=175, n_estimators=100, score=0.113, total=  55.4s\n",
      "[CV] criterion=entropy, max_depth=7, min_samples_split=175, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=7, min_samples_split=175, n_estimators=100, score=0.135, total=  56.5s\n",
      "[CV] criterion=entropy, max_depth=7, min_samples_split=175, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=7, min_samples_split=175, n_estimators=100, score=0.072, total=  56.0s\n",
      "[CV] criterion=entropy, max_depth=7, min_samples_split=175, n_estimators=150 \n",
      "[CV]  criterion=entropy, max_depth=7, min_samples_split=175, n_estimators=150, score=0.113, total= 1.4min\n",
      "[CV] criterion=entropy, max_depth=7, min_samples_split=175, n_estimators=150 \n",
      "[CV]  criterion=entropy, max_depth=7, min_samples_split=175, n_estimators=150, score=0.134, total= 1.5min\n",
      "[CV] criterion=entropy, max_depth=7, min_samples_split=175, n_estimators=150 \n",
      "[CV]  criterion=entropy, max_depth=7, min_samples_split=175, n_estimators=150, score=0.073, total= 1.4min\n",
      "[CV] criterion=entropy, max_depth=8, min_samples_split=75, n_estimators=75 \n",
      "[CV]  criterion=entropy, max_depth=8, min_samples_split=75, n_estimators=75, score=0.113, total=  47.9s\n",
      "[CV] criterion=entropy, max_depth=8, min_samples_split=75, n_estimators=75 \n",
      "[CV]  criterion=entropy, max_depth=8, min_samples_split=75, n_estimators=75, score=0.134, total=  48.7s\n",
      "[CV] criterion=entropy, max_depth=8, min_samples_split=75, n_estimators=75 \n",
      "[CV]  criterion=entropy, max_depth=8, min_samples_split=75, n_estimators=75, score=0.072, total=  47.0s\n",
      "[CV] criterion=entropy, max_depth=8, min_samples_split=75, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=8, min_samples_split=75, n_estimators=100, score=0.113, total= 1.0min\n",
      "[CV] criterion=entropy, max_depth=8, min_samples_split=75, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=8, min_samples_split=75, n_estimators=100, score=0.135, total= 1.0min\n",
      "[CV] criterion=entropy, max_depth=8, min_samples_split=75, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=8, min_samples_split=75, n_estimators=100, score=0.069, total= 1.0min\n",
      "[CV] criterion=entropy, max_depth=8, min_samples_split=75, n_estimators=150 \n",
      "[CV]  criterion=entropy, max_depth=8, min_samples_split=75, n_estimators=150, score=0.113, total= 1.6min\n",
      "[CV] criterion=entropy, max_depth=8, min_samples_split=75, n_estimators=150 \n",
      "[CV]  criterion=entropy, max_depth=8, min_samples_split=75, n_estimators=150, score=0.134, total= 1.6min\n",
      "[CV] criterion=entropy, max_depth=8, min_samples_split=75, n_estimators=150 \n",
      "[CV]  criterion=entropy, max_depth=8, min_samples_split=75, n_estimators=150, score=0.069, total= 1.6min\n",
      "[CV] criterion=entropy, max_depth=8, min_samples_split=125, n_estimators=75 \n",
      "[CV]  criterion=entropy, max_depth=8, min_samples_split=125, n_estimators=75, score=0.113, total=  47.5s\n",
      "[CV] criterion=entropy, max_depth=8, min_samples_split=125, n_estimators=75 \n",
      "[CV]  criterion=entropy, max_depth=8, min_samples_split=125, n_estimators=75, score=0.134, total=  47.3s\n",
      "[CV] criterion=entropy, max_depth=8, min_samples_split=125, n_estimators=75 \n",
      "[CV]  criterion=entropy, max_depth=8, min_samples_split=125, n_estimators=75, score=0.071, total=  47.0s\n",
      "[CV] criterion=entropy, max_depth=8, min_samples_split=125, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=8, min_samples_split=125, n_estimators=100, score=0.113, total= 1.1min\n",
      "[CV] criterion=entropy, max_depth=8, min_samples_split=125, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=8, min_samples_split=125, n_estimators=100, score=0.135, total= 1.1min\n",
      "[CV] criterion=entropy, max_depth=8, min_samples_split=125, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=8, min_samples_split=125, n_estimators=100, score=0.073, total= 1.0min\n",
      "[CV] criterion=entropy, max_depth=8, min_samples_split=125, n_estimators=150 \n",
      "[CV]  criterion=entropy, max_depth=8, min_samples_split=125, n_estimators=150, score=0.113, total= 1.6min\n",
      "[CV] criterion=entropy, max_depth=8, min_samples_split=125, n_estimators=150 \n",
      "[CV]  criterion=entropy, max_depth=8, min_samples_split=125, n_estimators=150, score=0.136, total= 1.6min\n",
      "[CV] criterion=entropy, max_depth=8, min_samples_split=125, n_estimators=150 \n",
      "[CV]  criterion=entropy, max_depth=8, min_samples_split=125, n_estimators=150, score=0.072, total= 1.5min\n",
      "[CV] criterion=entropy, max_depth=8, min_samples_split=175, n_estimators=75 \n",
      "[CV]  criterion=entropy, max_depth=8, min_samples_split=175, n_estimators=75, score=0.113, total=  46.2s\n",
      "[CV] criterion=entropy, max_depth=8, min_samples_split=175, n_estimators=75 \n",
      "[CV]  criterion=entropy, max_depth=8, min_samples_split=175, n_estimators=75, score=0.136, total=  46.0s\n",
      "[CV] criterion=entropy, max_depth=8, min_samples_split=175, n_estimators=75 \n",
      "[CV]  criterion=entropy, max_depth=8, min_samples_split=175, n_estimators=75, score=0.071, total=  46.3s\n",
      "[CV] criterion=entropy, max_depth=8, min_samples_split=175, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=8, min_samples_split=175, n_estimators=100, score=0.113, total= 1.0min\n",
      "[CV] criterion=entropy, max_depth=8, min_samples_split=175, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=8, min_samples_split=175, n_estimators=100, score=0.136, total= 1.1min\n",
      "[CV] criterion=entropy, max_depth=8, min_samples_split=175, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=8, min_samples_split=175, n_estimators=100, score=0.072, total= 1.0min\n",
      "[CV] criterion=entropy, max_depth=8, min_samples_split=175, n_estimators=150 \n",
      "[CV]  criterion=entropy, max_depth=8, min_samples_split=175, n_estimators=150, score=0.113, total= 1.6min\n",
      "[CV] criterion=entropy, max_depth=8, min_samples_split=175, n_estimators=150 \n",
      "[CV]  criterion=entropy, max_depth=8, min_samples_split=175, n_estimators=150, score=0.134, total= 1.6min\n",
      "[CV] criterion=entropy, max_depth=8, min_samples_split=175, n_estimators=150 \n",
      "[CV]  criterion=entropy, max_depth=8, min_samples_split=175, n_estimators=150, score=0.072, total= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 162 out of 162 | elapsed: 104.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=7,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=125,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [5, 7, 8],\n",
       "                         'min_samples_split': [75, 125, 175],\n",
       "                         'n_estimators': [75, 100, 150]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=10)"
      ]
     },
     "execution_count": 76,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid1 = {'criterion' : [\"gini\", \"entropy\"],\n",
    "              'max_depth' : [5, 7, 8], \n",
    "              'n_estimators': [75, 100, 150],\n",
    "               'min_samples_split':[75, 125, 175]}\n",
    "\n",
    "RF1_grid = GridSearchCV(RF1, param_grid=param_grid1, cv=3, verbose = 10)\n",
    "RF1_grid.fit(x_train, y_train1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ZJCmftJ2opH"
   },
   "outputs": [],
   "source": [
    "param_grid1 = {'criterion' : [\"gini\", \"entropy\"],\n",
    "              'max_depth' : [5, 7, 8], \n",
    "              'n_estimators': [75, 100, 150],\n",
    "               'min_samples_split':[75, 125, 175]}\n",
    "\n",
    "RF2_grid = GridSearchCV(RF2, param_grid=param_grid1, cv=3, verbose = 10)\n",
    "RF2_grid.fit(x_train, y_train2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'metric': ['euclidean', 'manhattan'],\n",
       "                         'n_neighbors': [3, 5, 9, 15],\n",
       "                         'weights': ['uniform', 'distance']})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_knn1 = {\n",
    "    'n_neighbors': [3, 5, 9, 15],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan'],\n",
    "}\n",
    "\n",
    "knn1_grid = GridSearchCV(knn1, param_grid_knn1, cv=3)\n",
    "knn1_grid.fit(x_train, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'metric': ['euclidean', 'manhattan'],\n",
       "                         'n_neighbors': [3, 5, 9, 15],\n",
       "                         'weights': ['uniform', 'distance']})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_knn2 = {\n",
    "    'n_neighbors': [3, 5, 9, 15],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan'],\n",
    "}\n",
    "\n",
    "knn2_grid = GridSearchCV(knn2, param_grid_knn2, cv=3)\n",
    "knn2_grid.fit(x_train, y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA - lsqr & eigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=LinearDiscriminantAnalysis(shrinkage='auto',\n",
       "                                                  solver='lsqr'),\n",
       "             param_grid={'shrinkage': array([0.  , 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 ,\n",
       "       0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 , 0.21,\n",
       "       0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 , 0.31, 0.32,\n",
       "       0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4 , 0.41, 0.42, 0.43,\n",
       "       0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5 , 0.51, 0.52, 0.53, 0.54,\n",
       "       0.55, 0.56, 0.57, 0.58, 0.59, 0.6 , 0.61, 0.62, 0.63, 0.64, 0.65,\n",
       "       0.66, 0.67, 0.68, 0.69, 0.7 , 0.71, 0.72, 0.73, 0.74, 0.75, 0.76,\n",
       "       0.77, 0.78, 0.79, 0.8 , 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87,\n",
       "       0.88, 0.89, 0.9 , 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98,\n",
       "       0.99]),\n",
       "                         'solver': ('lsqr', 'eigen')})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: SVD does not run w/ shrinkage\n",
    "param_grid_lda1 = {\n",
    "    'solver': ('lsqr', 'eigen'),\n",
    "    'shrinkage': np.arange(0, 1, 0.01),\n",
    "}\n",
    "\n",
    "lda1_grid = GridSearchCV(lda1, param_grid_lda1, cv=3)\n",
    "lda1_grid.fit(x_train, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=LinearDiscriminantAnalysis(shrinkage='auto',\n",
       "                                                  solver='lsqr'),\n",
       "             param_grid={'shrinkage': array([0.  , 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 ,\n",
       "       0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 , 0.21,\n",
       "       0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 , 0.31, 0.32,\n",
       "       0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4 , 0.41, 0.42, 0.43,\n",
       "       0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5 , 0.51, 0.52, 0.53, 0.54,\n",
       "       0.55, 0.56, 0.57, 0.58, 0.59, 0.6 , 0.61, 0.62, 0.63, 0.64, 0.65,\n",
       "       0.66, 0.67, 0.68, 0.69, 0.7 , 0.71, 0.72, 0.73, 0.74, 0.75, 0.76,\n",
       "       0.77, 0.78, 0.79, 0.8 , 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87,\n",
       "       0.88, 0.89, 0.9 , 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98,\n",
       "       0.99]),\n",
       "                         'solver': ('lsqr', 'eigen')})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVD does not run w/ shrinkage\n",
    "param_grid_lda2 = {\n",
    "    'solver': ('lsqr', 'eigen'),\n",
    "    'shrinkage': np.arange(0, 1, 0.01),\n",
    "}\n",
    "\n",
    "lda2_grid = GridSearchCV(lda2, param_grid_lda2, cv=3)\n",
    "lda2_grid.fit(x_train, y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA - svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LinearDiscriminantAnalysis(),\n",
       "             param_grid={'store_covariance': (True, False)})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_lda_svd1 = {\n",
    "    'store_covariance' : (True, False),\n",
    "}\n",
    "\n",
    "lda1_svd_grid = GridSearchCV(lda_svd1, param_grid_lda_svd1, cv=3)\n",
    "lda1_svd_grid.fit(x_train, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LinearDiscriminantAnalysis(),\n",
       "             param_grid={'store_covariance': (True, False)})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_lda_svd2 = {\n",
    "    'store_covariance' : (True, False),\n",
    "}\n",
    "\n",
    "lda2_svd_grid = GridSearchCV(lda_svd2, param_grid_lda_svd2, cv=3)\n",
    "lda2_svd_grid.fit(x_train, y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=QuadraticDiscriminantAnalysis(),\n",
       "             param_grid={'reg_param': (0, 1e-05, 0.0001, 0.001, 0.01, 0.1)})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_qda1 = {\n",
    "    'reg_param': (0, 0.00001, 0.0001, 0.001, 0.01, 0.1),\n",
    "}\n",
    "\n",
    "qda1_grid = GridSearchCV(qda1, param_grid_qda1, cv=3)\n",
    "qda1_grid.fit(x_train, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=QuadraticDiscriminantAnalysis(),\n",
       "             param_grid={'reg_param': (0, 1e-05, 0.0001, 0.001, 0.01, 0.1)})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_qda2 = {\n",
    "    'reg_param': (0, 0.00001, 0.0001, 0.001, 0.01, 0.1),\n",
    "}\n",
    "\n",
    "qda2_grid = GridSearchCV(qda2, param_grid_qda2, cv=3)\n",
    "qda2_grid.fit(x_train, y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=GaussianNB(),\n",
       "             param_grid={'var_smoothing': (0, 1e-09, 1e-07, 1e-05)})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_gnb1 = {\n",
    "    'var_smoothing': (0 ,1e-9, 1e-7, 1e-5),\n",
    "}\n",
    "\n",
    "gnb1_grid = GridSearchCV(gnb1, param_grid_gnb1, cv=3)\n",
    "gnb1_grid.fit(x_train, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=GaussianNB(),\n",
       "             param_grid={'var_smoothing': (0, 1e-09, 1e-07, 1e-05)})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_gnb2 = {\n",
    "    'var_smoothing': (0 ,1e-9, 1e-7, 1e-5),\n",
    "}\n",
    "\n",
    "gnb2_grid = GridSearchCV(gnb2, param_grid_gnb2, cv=3)\n",
    "gnb2_grid.fit(x_train, y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2i4OkCu7RZ5y"
   },
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plZ30Ay5_BL7"
   },
   "outputs": [],
   "source": [
    "crsp = pd.read_csv('crsp_filtered2.csv')\n",
    "#read a paper on how 60-20-20 is a good way to split up and train the data. So will be doing so\n",
    "train = crsp\n",
    "test = crsp\n",
    "x_cols = ['ret','mom3m','mom6m','mom12m'] # input features\n",
    "x = crsp[x_cols].values\n",
    "y = crsp['tgt_label'].values\n",
    "\n",
    "#running the data in the first set, will resplit the data after\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x ,y, train_size = 0.6, test_size=0.4, random_state=42)\n",
    "\n",
    "x_train\n",
    "x_test\n",
    "y_train\n",
    "y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LUDGZgMLAa15"
   },
   "outputs": [],
   "source": [
    "#Take the 40 and reinput, split into 20-20. \n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(\n",
    "    x_train, y_train, train_size = 0.6, test_size=0.4, random_state=42)\n",
    "\n",
    "x_train2\n",
    "x_test2\n",
    "y_train2\n",
    "y_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "24f6lGivAjZS"
   },
   "outputs": [],
   "source": [
    "#am going to run prediction on validation \n",
    "clf = MLPClassifier(hidden_layer_sizes=(32,32), \n",
    "                    activation='relu',\n",
    "                    alpha=0,\n",
    "                    max_iter=100,\n",
    "                    verbose=True,\n",
    "                    early_stopping=True,\n",
    "                    validation_fraction=0.65,\n",
    "                    n_iter_no_change=5\n",
    "                   )\n",
    "# merge back the combined datasets for training\n",
    "merge_x = np.concatenate((x_train2, x_train), axis=0)\n",
    "merge_y = np.concatenate((y_train2, y_train), axis=0)\n",
    "merge_x_t = np.concatenate((x_test2, x_test), axis=0)\n",
    "merge_y_t = np.concatenate((y_test2, y_test), axis=0)\n",
    "clf = clf.fit(merge_x , merge_y)\n",
    "\n",
    "clf.score(merge_x, merge_y) \n",
    "\n",
    "y_pred = clf.predict(merge_x_t)\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "# Prediction accuracy (compare with the test set accuracy above)\n",
    "metrics.accuracy_score(merge_y_t, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NT7nS8u_R_i5"
   },
   "source": [
    "### Hyperparamater tuning (mainly from demo code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6-ox5KkmA8dc"
   },
   "outputs": [],
   "source": [
    "# Parameters to test\n",
    "param_grid = {'alpha': [0, 1e-5, 1e-3], \n",
    "              'validation_fraction': [0.1,0.5]}\n",
    "\n",
    "grid = GridSearchCV(clf, param_grid, cv=3)\n",
    "grid.fit(merge_x, merge_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JN_iNeEzBCqR"
   },
   "outputs": [],
   "source": [
    "grid.best_params_\n",
    "\n",
    "# Best classifier\n",
    "best_clf = grid.best_estimator_\n",
    "\n",
    "# in-sample\n",
    "best_clf.score(merge_x, merge_y)\n",
    "\n",
    "# out-of-sample\n",
    "best_clf.score(merge_x_t, merge_y_t)\n",
    "\n",
    "y_pred = best_clf.predict(merge_x_t)\n",
    "metrics.accuracy_score(merge_y_t, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CmO5ZkZ-u31x"
   },
   "source": [
    "## Best Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMET_0VTxHme"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VE-w-_-Nsl3u",
    "outputId": "9fb4c4b4-1637-45e1-c8c0-4f66854ca055"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 7.742636826811269, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selected parameters\n",
    "MLR1_grid.best_params_\n",
    "\n",
    "# Best classifier\n",
    "MLR1_BR_clf = MLR1_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nq8Z5TtPxKnz",
    "outputId": "056702d3-e7dc-43b7-86b7-97845263f04b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 2.7825594022071245, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selected parameters\n",
    "MLR2_grid.best_params_\n",
    "\n",
    "# Best classifier\n",
    "MLR2_BR_clf = MLR2_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IU-oLvh2xPdk"
   },
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HKRrYlx7xUCC",
    "outputId": "bc4cd77d-9114-447c-a676-fb12b05251c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 100}"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selected parameters\n",
    "DR1_grid.best_params_\n",
    "\n",
    "# Best classifier\n",
    "DR1_BR_clf = DR1_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5LuKVxckyynv",
    "outputId": "71037448-2a14-4954-8019-de9afe1f42c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 125}"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selected parameters\n",
    "DR2_grid.best_params_\n",
    "\n",
    "# Best classifier\n",
    "DR2_BR_clf = DR2_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7CH7CxDS194F"
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p3q_Pvah1_uV"
   },
   "outputs": [],
   "source": [
    "# Selected parameters\n",
    "RF1_grid.best_params_\n",
    "\n",
    "# Best classifier\n",
    "RF1_BR_clf = RF1_grid.best_estimator_\n",
    "\n",
    "# Selected parameters\n",
    "RF2_grid.best_params_\n",
    "\n",
    "# Best classifier\n",
    "RF2_BR_clf = RF2_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'metric': 'manhattan', 'n_neighbors': 15, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn1_grid.best_params_\n",
    "knn1_BR_clf = knn1_grid.best_estimator_\n",
    "\n",
    "knn2_grid.best_params_\n",
    "knn2_BR_clf = knn2_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'shrinkage': 0.78, 'solver': 'lsqr'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'store_covariance': True}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'shrinkage': 0.12, 'solver': 'lsqr'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'store_covariance': True}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda1_grid.best_params_\n",
    "lda1_BR_clf = knn1_grid.best_estimator_\n",
    "\n",
    "lda1_svd_grid.best_params_\n",
    "lda_svd1_BR_clf = lda1_svd_grid.best_estimator_\n",
    "\n",
    "lda2_grid.best_params_\n",
    "lda2_BR_clf = knn2_grid.best_estimator_\n",
    "\n",
    "lda2_svd_grid.best_params_\n",
    "lda_svd2_BR_clf = lda2_svd_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reg_param': 0.001}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'reg_param': 0.1}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qda1_grid.best_params_\n",
    "qda1_BR_clf = lda1_grid.best_estimator_\n",
    "\n",
    "qda2_grid.best_params_\n",
    "qda2_BR_clf = lda2_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var_smoothing': 0}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'var_smoothing': 0}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb1_grid.best_params_\n",
    "gnb1_BR_clf = gnb1_grid.best_estimator_\n",
    "\n",
    "gnb2_grid.best_params_\n",
    "gnb2_BR_clf = gnb2_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QY0zLThxux_z"
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZaCYBqJx--m"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FuSrUOW_uMI4",
    "outputId": "3f7f48d0-d77e-4955-f516-0eda9f321fd7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12900246665341766"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.12821574143579742"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in-sample\n",
    "MLR1_BR_clf.score(x_train, y_train1)\n",
    "\n",
    "# out-of-sample\n",
    "MLR1_BR_clf.score(x_test, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3xVNEmoOyB85",
    "outputId": "66422dcd-70f7-4c03-898b-e9ee61bdb910"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49509591891607535"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.49693772318140045"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in-sample\n",
    "MLR2_BR_clf.score(x_train, y_train2)\n",
    "\n",
    "# out-of-sample\n",
    "MLR2_BR_clf.score(x_test, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6yaypg8ky6ZI"
   },
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AsRW0AVdy8b5",
    "outputId": "869e032d-df24-4ea3-9486-5d4ade2f2d1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12942916262377105"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.12475007190913491"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in-sample\n",
    "DR1_BR_clf.score(x_train, y_train1)\n",
    "\n",
    "# out-of-sample\n",
    "DR1_BR_clf.score(x_test, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_YqCvlISzmIa",
    "outputId": "e2516a92-692f-440a-a7c3-48aea3c1b520"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.497521656281783"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.4950786089616321"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in-sample\n",
    "DR2_BR_clf.score(x_train, y_train2)\n",
    "\n",
    "# out-of-sample\n",
    "DR2_BR_clf.score(x_test, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0S762jU2H0H"
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gMGfM-AS2KC1"
   },
   "outputs": [],
   "source": [
    "# in-sample\n",
    "RF1_BR_clf.score(x_train, y_train1)\n",
    "\n",
    "# out-of-sample\n",
    "RF1_BR_clf.score(x_test, y_test1)\n",
    "\n",
    "# in-sample\n",
    "RF2_BR_clf.score(x_train, y_train2)\n",
    "\n",
    "# out-of-sample\n",
    "RF2_BR_clf.score(x_test, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3755625957143358"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.10894409327842515"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.5747010205632387"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.45293634813843037"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in-sample\n",
    "knn1_BR_clf.score(x_train, y_train1)\n",
    "\n",
    "# out-of-sample\n",
    "knn1_BR_clf.score(x_test, y_test1)\n",
    "\n",
    "# in-sample\n",
    "knn2_BR_clf.score(x_train, y_train2)\n",
    "\n",
    "# out-of-sample\n",
    "knn2_BR_clf.score(x_test, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA - lsqr & eigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07627921113851838"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.07837744929529047"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.4939327340105914"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.5075381819967588"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in-sample\n",
    "lda1_BR_clf.score(x_train, y_train1)\n",
    "\n",
    "# out-of-sample\n",
    "lda1_BR_clf.score(x_test, y_test1)\n",
    "\n",
    "# in-sample\n",
    "lda2_BR_clf.score(x_train, y_train2)\n",
    "\n",
    "# out-of-sample\n",
    "lda2_BR_clf.score(x_test, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA - svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12935317567014648"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.12798422909899607"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.49504915771384483"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.4974358254817912"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in-sample\n",
    "lda_svd1_BR_clf.score(x_train, y_train1)\n",
    "\n",
    "# out-of-sample\n",
    "lda_svd1_BR_clf.score(x_test, y_test1)\n",
    "\n",
    "# in-sample\n",
    "lda_svd2_BR_clf.score(x_train, y_train2)\n",
    "\n",
    "# out-of-sample\n",
    "lda_svd2_BR_clf.score(x_test, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1296220525829719"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.1288541542433405"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.4946867583965584"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.49702190948569186"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in-sample\n",
    "qda1_BR_clf.score(x_train, y_train1)\n",
    "\n",
    "# out-of-sample\n",
    "qda1_BR_clf.score(x_test, y_test1)\n",
    "\n",
    "# in-sample\n",
    "qda2_BR_clf.score(x_train, y_train2)\n",
    "\n",
    "# out-of-sample\n",
    "qda2_BR_clf.score(x_test, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12447247518733706"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.12351533944619443"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.4887539308635625"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.48038809886278333"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in-sample\n",
    "gnb1_BR_clf.score(x_train, y_train1)\n",
    "\n",
    "# out-of-sample\n",
    "gnb1_BR_clf.score(x_test, y_test1)\n",
    "\n",
    "# in-sample\n",
    "gnb2_BR_clf.score(x_train, y_train2)\n",
    "\n",
    "# out-of-sample\n",
    "gnb2_BR_clf.score(x_test, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Vfu1QDfuvh0"
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aekmeMp3yOhn"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TAjal8EsuUU6",
    "outputId": "48d9e5bd-5cab-4ab9-fea7-d8417d3481ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12821574143579742"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLR1_y_pred1 = MLR1_BR_clf.predict(x_test)\n",
    "metrics.accuracy_score(y_test1, MLR1_y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z_ADQ0BAuphp",
    "outputId": "e4e7ecf5-53c8-4983-beef-e351a7843214"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49693772318140045"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLR2_y_pred2 = MLR2_BR_clf.predict(x_test)\n",
    "metrics.accuracy_score(y_test2, MLR2_y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JmQVChizBD4"
   },
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t3kf3sjZyM7R",
    "outputId": "45499869-cfda-4534-81ab-0a84adb209b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12475007190913491"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DR1_y_pred1 = DR1_BR_clf.predict(x_test)\n",
    "metrics.accuracy_score(y_test1, DR1_y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J_K3RHbbzGux",
    "outputId": "055af2c1-7b15-4be5-9ec0-539cc27cd53c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4950786089616321"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DR2_y_pred2 = DR2_BR_clf.predict(x_test)\n",
    "metrics.accuracy_score(y_test2, DR2_y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kokpyZOZ2YC_"
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dlC-UBvczuoF"
   },
   "outputs": [],
   "source": [
    "RF1_y_pred1 = RF1_BR_clf.predict(x_test)\n",
    "metrics.accuracy_score(y_test1, RF1_y_pred1)\n",
    "\n",
    "RF2_y_pred2 = RF2_BR_clf.predict(x_test)\n",
    "metrics.accuracy_score(y_test2, RF2_y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10894409327842515"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.45293634813843037"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn1_y_pred1 = knn1_BR_clf.predict(x_test)\n",
    "metrics.accuracy_score(y_test1, knn1_y_pred1)\n",
    "\n",
    "knn2_y_pred2 = knn2_BR_clf.predict(x_test)\n",
    "metrics.accuracy_score(y_test2, knn2_y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA - lsqr & eigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07837744929529047"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.5075381819967588"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda1_y_pred1 = lda1_BR_clf.predict(x_test)\n",
    "metrics.accuracy_score(y_test1, lda1_y_pred1)\n",
    "\n",
    "lda2_y_pred2 = lda2_BR_clf.predict(x_test)\n",
    "metrics.accuracy_score(y_test2, lda2_y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA - svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12798422909899607"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.4974358254817912"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_svd1_y_pred1 = lda_svd1_BR_clf.predict(x_test)\n",
    "metrics.accuracy_score(y_test1, lda_svd1_y_pred1)\n",
    "\n",
    "lda_svd2_y_pred1 = lda_svd2_BR_clf.predict(x_test)\n",
    "metrics.accuracy_score(y_test2, lda_svd2_y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1288541542433405"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.49702190948569186"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qda1_y_pred1 = qda1_BR_clf.predict(x_test)\n",
    "metrics.accuracy_score(y_test1, qda1_y_pred1)\n",
    "\n",
    "qda2_y_pred2 = qda2_BR_clf.predict(x_test)\n",
    "metrics.accuracy_score(y_test2, qda2_y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12351533944619443"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.48038809886278333"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb1_y_pred1 = gnb1_BR_clf.predict(x_test)\n",
    "metrics.accuracy_score(y_test1, gnb1_y_pred1)\n",
    "\n",
    "gnb2_y_pred2 = gnb2_BR_clf.predict(x_test)\n",
    "metrics.accuracy_score(y_test2, gnb2_y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_-mN3uE3Myy"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lpum6OUl3PqE"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hgm9CPfY3R95"
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy Score TGT1:\", accuracy_score(y_test1, MLR1_y_pred1) )\n",
    "print(\"Accuracy Score TGT2:\", accuracy_score(y_test2, MLR2_y_pred2) )\n",
    "print(\"Precision TGT1:\", precision_score(y_test1, MLR1_y_pred1, average = 'weighted') )\n",
    "print(\"Precision TGT2:\", precision_score(y_test2, MLR2_y_pred2, average = 'weighted') )\n",
    "print(\"Recall TGT1:\", recall_score(y_test1, MLR1_y_pred1, average = 'weighted'))\n",
    "print(\"Recall TGT2:\", recall_score(y_test2, MLR2_y_pred2, average = 'weighted'))\n",
    "print(\"F1 TGT1:\", f1_score(y_test1, MLR1_y_pred1, average = 'weighted'))\n",
    "print(\"F1 TGT2:\", f1_score(y_test2, MLR2_y_pred2, average = 'weighted'))\n",
    "print(\"\\n classification report TGT1:\\n\", classification_report(y_test1, MLR1_y_pred1))\n",
    "print(\"\\n classification report TGT2:\\n\", classification_report(y_test2, MLR2_y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOqXLvQb4gr0"
   },
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2UkUby1C4jBK"
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy Score TGT1:\", accuracy_score(y_test1, DR1_y_pred1) )\n",
    "print(\"Accuracy Score TGT2:\", accuracy_score(y_test2, DR2_y_pred2) )\n",
    "print(\"Precision TGT1:\", precision_score(y_test1, DR1_y_pred1, average = 'weighted') )\n",
    "print(\"Precision TGT2:\", precision_score(y_test2, DR2_y_pred2, average = 'weighted') )\n",
    "print(\"Recall TGT1:\", recall_score(y_test1, DR1_y_pred1, average = 'weighted'))\n",
    "print(\"Recall TGT2:\", recall_score(y_test2, DR2_y_pred2, average = 'weighted'))\n",
    "print(\"F1 TGT1:\", f1_score(y_test1, DR1_y_pred1, average = 'weighted'))\n",
    "print(\"F1 TGT2:\", f1_score(y_test2, DR2_y_pred2, average = 'weighted'))\n",
    "print(\"\\n classification report TGT1:\\n\", classification_report(y_test1, DR1_y_pred1))\n",
    "print(\"\\n classification report TGT2:\\n\", classification_report(y_test2, DR2_y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMTHBwiF43aZ"
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MxrMQ71J45C5"
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy Score TGT1:\", accuracy_score(y_test1, RF1_y_pred1) )\n",
    "print(\"Accuracy Score TGT2:\", accuracy_score(y_test2, RF2_y_pred2) )\n",
    "print(\"Precision TGT1:\", precision_score(y_test1, RF1_y_pred1, average = 'weighted') )\n",
    "print(\"Precision TGT2:\", precision_score(y_test2, RF2_y_pred2, average = 'weighted') )\n",
    "print(\"Recall TGT1:\", recall_score(y_test1, RF1_y_pred1, average = 'weighted'))\n",
    "print(\"Recall TGT2:\", recall_score(y_test2, RF2_y_pred2, average = 'weighted'))\n",
    "print(\"F1 TGT1:\", f1_score(y_test1, RF1_y_pred1, average = 'weighted'))\n",
    "print(\"F1 TGT2:\", f1_score(y_test2, RF2_y_pred2, average = 'weighted'))\n",
    "print(\"\\n classification report TGT1:\\n\", classification_report(y_test1, RF1_y_pred1))\n",
    "print(\"\\n classification report TGT2:\\n\", classification_report(y_test2, RF2_y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score TGT1: 0.10894409327842515\n",
      "Accuracy Score TGT2: 0.4411993742151381\n",
      "Precision TGT1: 0.11183709448435088\n",
      "Precision TGT2: 0.4268213606176114\n",
      "Recall TGT1: 0.10894409327842515\n",
      "Recall TGT2: 0.45293634813843037\n",
      "F1 TGT1: 0.10589029819228506\n",
      "F1 TGT2: 0.43285934891256234\n",
      "\n",
      " classification report TGT1:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.09      0.21      0.13     11158\n",
      "         1.0       0.11      0.17      0.13     15253\n",
      "         2.0       0.11      0.14      0.13     16200\n",
      "         3.0       0.12      0.11      0.12     16447\n",
      "         4.0       0.13      0.09      0.11     16222\n",
      "         5.0       0.13      0.08      0.10     15831\n",
      "         6.0       0.11      0.08      0.09     15429\n",
      "         7.0       0.10      0.07      0.08     14489\n",
      "         8.0       0.10      0.08      0.09     12714\n",
      "         9.0       0.09      0.08      0.08      8798\n",
      "\n",
      "    accuracy                           0.11    142541\n",
      "   macro avg       0.11      0.11      0.10    142541\n",
      "weighted avg       0.11      0.11      0.11    142541\n",
      "\n",
      "\n",
      " classification report TGT2:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.39      0.50      0.44     55311\n",
      "         0.0       0.11      0.01      0.02     14887\n",
      "         1.0       0.52      0.51      0.51     72343\n",
      "\n",
      "    accuracy                           0.45    142541\n",
      "   macro avg       0.34      0.34      0.32    142541\n",
      "weighted avg       0.43      0.45      0.43    142541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score TGT1:\", accuracy_score(y_test1, knn1_y_pred1) )\n",
    "print(\"Accuracy Score TGT2:\", accuracy_score(y_test2, knn2_y_pred2) )\n",
    "print(\"Precision TGT1:\", precision_score(y_test1, knn1_y_pred1, average = 'weighted') )\n",
    "print(\"Precision TGT2:\", precision_score(y_test2, knn2_y_pred2, average = 'weighted') )\n",
    "print(\"Recall TGT1:\", recall_score(y_test1, knn1_y_pred1, average = 'weighted'))\n",
    "print(\"Recall TGT2:\", recall_score(y_test2, knn2_y_pred2, average = 'weighted'))\n",
    "print(\"F1 TGT1:\", f1_score(y_test1, knn1_y_pred1, average = 'weighted'))\n",
    "print(\"F1 TGT2:\", f1_score(y_test2, knn2_y_pred2, average = 'weighted'))\n",
    "print(\"\\n classification report TGT1:\\n\", classification_report(y_test1, knn1_y_pred1))\n",
    "print(\"\\n classification report TGT2:\\n\", classification_report(y_test2, knn2_y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA - lsqr & eigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score TGT1: 0.07837744929529047\n",
      "Accuracy Score TGT2: 0.5075381819967588\n",
      "Precision TGT1: 0.018357675048675758\n",
      "Precision TGT2: 0.5486112238967392\n",
      "Recall TGT1: 0.07837744929529047\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Recall TGT2: 0.5075381819967588\n",
      "F1 TGT1: 0.01286594498427558\n",
      "F1 TGT2: 0.3417706095399292\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " classification report TGT1:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.08      0.99      0.14     11158\n",
      "         1.0       0.00      0.00      0.00     15253\n",
      "         2.0       0.00      0.00      0.00     16200\n",
      "         3.0       0.00      0.00      0.00     16447\n",
      "         4.0       0.00      0.00      0.00     16222\n",
      "         5.0       0.00      0.00      0.00     15831\n",
      "         6.0       0.00      0.00      0.00     15429\n",
      "         7.0       0.00      0.00      0.00     14489\n",
      "         8.0       0.00      0.00      0.00     12714\n",
      "         9.0       0.20      0.01      0.03      8798\n",
      "\n",
      "    accuracy                           0.08    142541\n",
      "   macro avg       0.03      0.10      0.02    142541\n",
      "weighted avg       0.02      0.08      0.01    142541\n",
      "\n",
      "\n",
      " classification report TGT2:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.75      0.00      0.00     55311\n",
      "         0.0       0.00      0.00      0.00     14887\n",
      "         1.0       0.51      1.00      0.67     72343\n",
      "\n",
      "    accuracy                           0.51    142541\n",
      "   macro avg       0.42      0.33      0.22    142541\n",
      "weighted avg       0.55      0.51      0.34    142541\n",
      "\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score TGT1:\", accuracy_score(y_test1, lda1_y_pred1) )\n",
    "print(\"Accuracy Score TGT2:\", accuracy_score(y_test2, lda2_y_pred2) )\n",
    "print(\"Precision TGT1:\", precision_score(y_test1, lda1_y_pred1, average = 'weighted') )\n",
    "print(\"Precision TGT2:\", precision_score(y_test2, lda2_y_pred2, average = 'weighted') )\n",
    "print(\"Recall TGT1:\", recall_score(y_test1, lda1_y_pred1, average = 'weighted'))\n",
    "print(\"Recall TGT2:\", recall_score(y_test2, lda2_y_pred2, average = 'weighted'))\n",
    "print(\"F1 TGT1:\", f1_score(y_test1, lda1_y_pred1, average = 'weighted'))\n",
    "print(\"F1 TGT2:\", f1_score(y_test2, lda2_y_pred2, average = 'weighted'))\n",
    "print(\"\\n classification report TGT1:\\n\", classification_report(y_test1, lda1_y_pred1))\n",
    "print(\"\\n classification report TGT2:\\n\", classification_report(y_test2, lda2_y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA - svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score TGT1: 0.12798422909899607\n",
      "Accuracy Score TGT2: 0.4974358254817912\n",
      "Precision TGT1: 0.12284390897824418\n",
      "Precision TGT2: 0.4338602704017685\n",
      "Recall TGT1: 0.12798422909899607\n",
      "Recall TGT2: 0.4974358254817912\n",
      "F1 TGT1: 0.10067244874579065\n",
      "F1 TGT2: 0.4006692399409426\n",
      "\n",
      " classification report TGT1:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.16      0.11      0.13     11158\n",
      "         1.0       0.12      0.09      0.11     15253\n",
      "         2.0       0.12      0.17      0.14     16200\n",
      "         3.0       0.13      0.20      0.16     16447\n",
      "         4.0       0.13      0.44      0.20     16222\n",
      "         5.0       0.10      0.01      0.02     15831\n",
      "         6.0       0.10      0.03      0.05     15429\n",
      "         7.0       0.11      0.01      0.01     14489\n",
      "         8.0       0.12      0.03      0.05     12714\n",
      "         9.0       0.16      0.13      0.14      8798\n",
      "\n",
      "    accuracy                           0.13    142541\n",
      "   macro avg       0.13      0.12      0.10    142541\n",
      "weighted avg       0.12      0.13      0.10    142541\n",
      "\n",
      "\n",
      " classification report TGT2:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.40      0.12      0.18     55311\n",
      "         0.0       0.18      0.00      0.00     14887\n",
      "         1.0       0.51      0.89      0.65     72343\n",
      "\n",
      "    accuracy                           0.50    142541\n",
      "   macro avg       0.36      0.34      0.28    142541\n",
      "weighted avg       0.43      0.50      0.40    142541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score TGT1:\", accuracy_score(y_test1, lda_svd1_y_pred1) )\n",
    "print(\"Accuracy Score TGT2:\", accuracy_score(y_test2, lda_svd2_y_pred2) )\n",
    "print(\"Precision TGT1:\", precision_score(y_test1, lda_svd1_y_pred1, average = 'weighted') )\n",
    "print(\"Precision TGT2:\", precision_score(y_test2, lda_svd2_y_pred2, average = 'weighted') )\n",
    "print(\"Recall TGT1:\", recall_score(y_test1, lda_svd1_y_pred1, average = 'weighted'))\n",
    "print(\"Recall TGT2:\", recall_score(y_test2, lda_svd2_y_pred2, average = 'weighted'))\n",
    "print(\"F1 TGT1:\", f1_score(y_test1, lda_svd1_y_pred1, average = 'weighted'))\n",
    "print(\"F1 TGT2:\", f1_score(y_test2, lda_svd2_y_pred2, average = 'weighted'))\n",
    "print(\"\\n classification report TGT1:\\n\", classification_report(y_test1, lda_svd1_y_pred1))\n",
    "print(\"\\n classification report TGT2:\\n\", classification_report(y_test2, lda_svd2_y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score TGT1: 0.1288541542433405\n",
      "Accuracy Score TGT2: 0.49702190948569186\n",
      "Precision TGT1: 0.12355071906801725\n",
      "Precision TGT2: 0.41492783728056015\n",
      "Recall TGT1: 0.1288541542433405\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Recall TGT2: 0.49702190948569186\n",
      "F1 TGT1: 0.1081876813380111\n",
      "F1 TGT2: 0.4023872998924251\n",
      "\n",
      " classification report TGT1:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.14      0.15      0.15     11158\n",
      "         1.0       0.13      0.09      0.10     15253\n",
      "         2.0       0.12      0.17      0.14     16200\n",
      "         3.0       0.13      0.29      0.18     16447\n",
      "         4.0       0.13      0.30      0.18     16222\n",
      "         5.0       0.11      0.03      0.04     15831\n",
      "         6.0       0.11      0.05      0.07     15429\n",
      "         7.0       0.11      0.01      0.03     14489\n",
      "         8.0       0.12      0.03      0.05     12714\n",
      "         9.0       0.16      0.12      0.14      8798\n",
      "\n",
      "    accuracy                           0.13    142541\n",
      "   macro avg       0.13      0.12      0.11    142541\n",
      "weighted avg       0.12      0.13      0.11    142541\n",
      "\n",
      "\n",
      " classification report TGT2:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.40      0.13      0.19     55311\n",
      "         0.0       0.00      0.00      0.00     14887\n",
      "         1.0       0.51      0.88      0.65     72343\n",
      "\n",
      "    accuracy                           0.50    142541\n",
      "   macro avg       0.30      0.34      0.28    142541\n",
      "weighted avg       0.41      0.50      0.40    142541\n",
      "\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score TGT1:\", accuracy_score(y_test1, qda1_y_pred1) )\n",
    "print(\"Accuracy Score TGT2:\", accuracy_score(y_test2, qda2_y_pred2) )\n",
    "print(\"Precision TGT1:\", precision_score(y_test1, qda1_y_pred1, average = 'weighted') )\n",
    "print(\"Precision TGT2:\", precision_score(y_test2, qda2_y_pred2, average = 'weighted') )\n",
    "print(\"Recall TGT1:\", recall_score(y_test1, qda1_y_pred1, average = 'weighted'))\n",
    "print(\"Recall TGT2:\", recall_score(y_test2, qda2_y_pred2, average = 'weighted'))\n",
    "print(\"F1 TGT1:\", f1_score(y_test1, qda1_y_pred1, average = 'weighted'))\n",
    "print(\"F1 TGT2:\", f1_score(y_test2, qda2_y_pred2, average = 'weighted'))\n",
    "print(\"\\n classification report TGT1:\\n\", classification_report(y_test1, qda1_y_pred1))\n",
    "print(\"\\n classification report TGT2:\\n\", classification_report(y_test2, qda2_y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score TGT1: 0.12351533944619443\n",
      "Accuracy Score TGT2: 0.48038809886278333\n",
      "Precision TGT1: 0.12055495715324052\n",
      "Precision TGT2: 0.4331366053269798\n",
      "Recall TGT1: 0.12351533944619443\n",
      "Recall TGT2: 0.48038809886278333\n",
      "F1 TGT1: 0.07455037336058991\n",
      "F1 TGT2: 0.40597153997299135\n",
      "\n",
      " classification report TGT1:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.19      0.04      0.07     11158\n",
      "         1.0       0.13      0.03      0.05     15253\n",
      "         2.0       0.10      0.01      0.02     16200\n",
      "         3.0       0.13      0.64      0.21     16447\n",
      "         4.0       0.09      0.03      0.04     16222\n",
      "         5.0       0.11      0.25      0.15     15831\n",
      "         6.0       0.09      0.02      0.03     15429\n",
      "         7.0       0.11      0.01      0.02     14489\n",
      "         8.0       0.14      0.01      0.02     12714\n",
      "         9.0       0.17      0.11      0.13      8798\n",
      "\n",
      "    accuracy                           0.12    142541\n",
      "   macro avg       0.12      0.12      0.07    142541\n",
      "weighted avg       0.12      0.12      0.07    142541\n",
      "\n",
      "\n",
      " classification report TGT2:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.42      0.13      0.20     55311\n",
      "         0.0       0.12      0.06      0.08     14887\n",
      "         1.0       0.51      0.84      0.63     72343\n",
      "\n",
      "    accuracy                           0.48    142541\n",
      "   macro avg       0.35      0.34      0.30    142541\n",
      "weighted avg       0.43      0.48      0.41    142541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score TGT1:\", accuracy_score(y_test1, gnb1_y_pred1) )\n",
    "print(\"Accuracy Score TGT2:\", accuracy_score(y_test2, gnb2_y_pred2) )\n",
    "print(\"Precision TGT1:\", precision_score(y_test1, gnb1_y_pred1, average = 'weighted') )\n",
    "print(\"Precision TGT2:\", precision_score(y_test2, gnb2_y_pred2, average = 'weighted') )\n",
    "print(\"Recall TGT1:\", recall_score(y_test1, gnb1_y_pred1, average = 'weighted'))\n",
    "print(\"Recall TGT2:\", recall_score(y_test2, gnb2_y_pred2, average = 'weighted'))\n",
    "print(\"F1 TGT1:\", f1_score(y_test1, gnb1_y_pred1, average = 'weighted'))\n",
    "print(\"F1 TGT2:\", f1_score(y_test2, gnb2_y_pred2, average = 'weighted'))\n",
    "print(\"\\n classification report TGT1:\\n\", classification_report(y_test1, gnb1_y_pred1))\n",
    "print(\"\\n classification report TGT2:\\n\", classification_report(y_test2, gnb2_y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Cp6tyYpzwzp5",
    "L8t9NZ-Ixc4U"
   ],
   "name": "Full Case.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
