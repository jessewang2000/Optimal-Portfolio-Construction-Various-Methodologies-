{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import inv,norm\n",
    "from scipy.special import beta,betainc\n",
    "from sklearn.linear_model import LassoLars, lars_path\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mean and covariance matrix of the 100 assets and 3 factors\n",
    "mu = pd.read_csv('mean.csv',header=None)\n",
    "S = pd.read_csv('var.csv',header=None)\n",
    "mu = mu.drop(0,axis=1)\n",
    "S = S.drop(0,axis=1)\n",
    "mu = np.asarray(mu).flatten()\n",
    "S = np.asarray(S)\n",
    "\n",
    "# Set parameters for the optimization problem\n",
    "sigma = 0.04   # target standard deviation\n",
    "N = 103        # number of assets \n",
    "K = 3          # number of factors\n",
    "T = 240        # number of time series observations\n",
    "K_fold = 10     # number of folds for cross-validation\n",
    "nobs = 100     # number of simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_s = np.zeros(nobs)\n",
    "os_sr = np.zeros(nobs)\n",
    "for i in range(nobs):\n",
    "    r = np.random.multivariate_normal(mu, S, T)\n",
    "    muh = np.mean(r, axis = 0)\n",
    "    sh = np.cov(r, rowvar = False, ddof = 0)\n",
    "    wh = np.dot(inv(sh), muh)\n",
    "    wh = sigma/np.sqrt(np.dot(wh,muh))*wh\n",
    "    # print out wh\n",
    "    os_s[i] = np.sqrt(np.dot(wh,S.dot(wh)))\n",
    "    os_sr[i] = np.sqrt(12)*np.dot(wh,mu)/os_s[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Std dev: 0.07014086458178607\n",
      "Sharpe Ratio: 0.9360672029432878\n",
      "Theortical Maximum Sharpe Ratio: 1.8824247694760523\n"
     ]
    }
   ],
   "source": [
    "# Average out of sample std dev across simulations and the sharpe ratio\n",
    "# Followed by the Maximum Sharpe Ratio\n",
    "print(\"Std dev:\", np.mean(os_s))\n",
    "print(\"Sharpe Ratio:\", np.mean(os_sr) )\n",
    "print(\"Theortical Maximum Sharpe Ratio:\", np.sqrt(12*np.dot(mu,inv(S).dot(mu))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theta_adj(theta,N,T):      # from smple code, needed for maxser\n",
    "    a = N/2\n",
    "    b = (T-N)/2\n",
    "    theta_a = ((T-N-2)*theta-N)/T+2*theta**a*(1+theta)**(-(T-2)/2)/T/(betainc(a,b,theta/(1+theta))*beta(a,b))\n",
    "    return theta_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAXSER(r, sigma,Kfold):\n",
    "    T,N = r.shape\n",
    "    muh = np.mean(r, axis = 0)\n",
    "    # from sample code\n",
    "    sh = np.cov(r, rowvar = False, ddof = 0)\n",
    "    theta = np.dot(muh,inv(Sh).dot(muh))\n",
    "    theta_a = theta_adj(theta, N, T)\n",
    "    rc = (1+theta_a)/np.sqrt(theta_a)*sigma\n",
    "    zeta = np.zeros(Kfold)\n",
    "    T1 = np.fix(T/Kfold).astype(int)\n",
    "    y1 = rc*np.ones(T-T1)\n",
    "    \n",
    "    #find optimal Zeta with K-fold cross validation \n",
    "    for i in range(Kfold):\n",
    "        ind = range(T1*i, (i+1)*T1)\n",
    "        r1 = np.delete(r, ind, axis = 0)\n",
    "        _, _, b1 = lars_path(r1, y1, method = 'lasso')\n",
    "        q = np.std(np.matmul(r[ind, :], b1), axis = 0, ddof = 1)\n",
    "        j = np.argmin(np.abs(sigma-q))\n",
    "        zeta[i] = norm(b1[:,j], 1)/norm(b1[:, -1], 1)\n",
    "    zeta = np.mean(zeta)\n",
    "    y = rc*np.ones(T)\n",
    "    _,_, b = lars_path(r,y, method= 'lasso')\n",
    "    zeta0 = norm(b,1,axis = 0)/norm(b[:,-1],1)\n",
    "    ind = np.min(np.argwhere(zeta < zeta0))\n",
    "    q = (zeta - zeta0[ind-1])/(zeta0[ind] - zeta0[ind-1])\n",
    "    w = (1-q)*b[:, ind-1]+q*b[:, ind]\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Std dev: 0.04078653518625468\n",
      "Sharpe Ratio: 1.249525638777942\n"
     ]
    }
   ],
   "source": [
    "os_s_mx= np.zeros(nobs)\n",
    "os_sr_mx= np.zeros(nobs)\n",
    "for i in range(nobs):\n",
    "    # from demo code\n",
    "    r = np.random.multivariate_normal(mu,S,T)   \n",
    "    muh = np.mean(r,axis=0)\n",
    "    Sh = np.cov(r,rowvar=False,ddof=0)\n",
    "    \n",
    "    series = MAXSER(r,sigma,K_fold)\n",
    "    os_s_mx[i] = np.sqrt(np.dot(series,S.dot(series)))\n",
    "    os_sr_mx[i] = np.sqrt(12)*np.dot(series,mu)/os_s_mx[i]\n",
    "\n",
    "# Average out of sample std dev across simulations and the sharpe ratio\n",
    "# Followed by the Maximum Sharpe Ratio\n",
    "print(\"Std dev:\", np.mean(os_s_mx))\n",
    "print(\"Sharpe Ratio:\", np.mean(np.mean(os_sr_mx)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge(alpha,trset,valset,sigma = 0.04):   \n",
    "    \n",
    "    T,N = trset.shape\n",
    "    muh = np.mean(trset,axis=0)\n",
    "    Sh = np.cov(trset,rowvar=False,ddof=0)\n",
    "    theta = np.dot(muh,inv(Sh).dot(muh))\n",
    "    theta_a = theta_adj(theta,N,len(trset))    \n",
    "    rc = (1+theta_a)/np.sqrt(theta_a)*sigma\n",
    "    y = rc*np.ones(T)\n",
    "    w = np.matmul(inv(np.matmul(trset.T,trset)+ np.eye(N)*alpha),np.matmul(trset.T,y))\n",
    "    rh = valset.dot(w)\n",
    "    os_s = np.std(rh, ddof =1)\n",
    "    return os_s  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findridge(alpha,trset,valset,sigma):\n",
    "    return ridge(alpha,trset,valset) - sigma\n",
    "\n",
    "#need to find opitmal alpha now\n",
    "\n",
    "def Ridge_function(r,sigma,K_fold):\n",
    "    \"\"\"\n",
    "    Performs K_fold validation to find the best alpha - tuning parameter- for the ridge regression for every fold,\n",
    "    then averages those best alphas to return the optimal alpha.\n",
    "    \"\"\"\n",
    "    \n",
    "    alphas=[]\n",
    "    \n",
    "    T,N = r.shape\n",
    "    muh = np.mean(r,axis=0)\n",
    "    Sh = np.cov(r,rowvar=False,ddof=0)\n",
    "    theta = np.dot(muh,inv(Sh).dot(muh))\n",
    "    theta_a = theta_adj(theta,N,T)   \n",
    "    rc = (1+theta_a)/np.sqrt(theta_a)*sigma\n",
    "    zeta = np.zeros(K_fold)\n",
    "    T1 = np.fix(T/K_fold).astype(int)    #number of data in each fold\n",
    "    y1 = rc*np.ones(T-T1)\n",
    "    \n",
    "    #use K-fold cross validation to find the optimal zeta\n",
    "    for i in range(K_fold):\n",
    "        ind = range(i*T1,(i+1)*T1)     #index of beginninG and end of the selected fold \n",
    "        r1 = np.delete(r,ind,axis=0)  # rest of data after deleting the selected fold\n",
    "        \n",
    "        best_alpha = scipy.optimize.brentq(f, 0,50, args=(r1,r[ind,:],sigma))    \n",
    "        alphas.append(best_alpha)\n",
    "    \n",
    "    opt_alpha = sum(alphas) / len(alphas)\n",
    "    return opt_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
